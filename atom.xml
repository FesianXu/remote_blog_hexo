<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>机器学习杂货铺2号店</title>
  
  <subtitle>Machine Learning Store Num. 2. The records of my learning and life chores.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.csdn.net/LoseInVain/"/>
  <updated>2018-10-22T07:28:01.351Z</updated>
  <id>https://blog.csdn.net/LoseInVain/</id>
  
  <author>
    <name>徐飞翔(Fesian Xu)</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>概率学派和贝叶斯学派的区别</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/22/basic/freqs_bayesian/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/22/basic/freqs_bayesian/</id>
    <published>2018-10-22T07:24:18.674Z</published>
    <updated>2018-10-22T07:28:01.351Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br><strong>对于一个数学模型来说，最主要的莫过于根据观察到的数据进行模型的参数估计了，而概率学派和贝叶斯学派对于这个参数估计有着不同的做法，接下来我们讨论下。</strong></p><p><strong>如有谬误，请联系指正。转载请注明出处。</strong></p><p><em>联系方式：</em><br><strong>e-mail</strong>: <code>FesianXu@163.com</code><br><strong>QQ</strong>: <code>973926198</code><br><strong>github</strong>: <code>https://github.com/FesianXu</code><br><strong>code</strong>: </p><hr><h1 id="概率派和贝叶斯派的区别"><a href="#概率派和贝叶斯派的区别" class="headerlink" title="概率派和贝叶斯派的区别"></a>概率派和贝叶斯派的区别</h1><p>对于一个问题，从概率派和贝叶斯派看起来是完全不一样的，其最主要的区别就是对于一个问题中模型参数的“信仰”：</p><ul><li>对于频率派学者来说，一个模型中的参数是“固定”的，而数据是在分布中随机采样的。我们要<strong>重点</strong>理解这个固定，这里指的固定意思是</li></ul><blockquote><p>对于一个模型或者也可说一个分布中的参数，我们相信它是固定不变的，而我们观察（采样）到的数据是这个分布中的一个独立同分布样本。也就是说，我们相信这个分布的参数不管你怎么采样，根据参数对其的估计都应该是不会变的，They remain constant!如果根据数据估计出来的参数和真实模型不符合，只可能是引入了噪声而已。<strong>在这个观点中，模型参数才是上帝，数据为之服务。</strong></p></blockquote><ul><li>对于贝叶斯派学者来说，我们观察到的数据才是“固定”的，而我们的模型的参数才是在一直变化的。我们不停地观察数据，估计出来的模型参数就可能一直的变化。不仅如此，我们对于这个模型的参数可能会有一个最初始的信仰，称之为<strong>先验假设</strong>，一旦设置后了之后，我们就可以听由观察到的数据指导模型参数更新了。在这种观点中，我们的模型参数不再是一个参数，而是一个分布了。一般来说，对于贝叶斯派，有公式：<script type="math/tex; mode=display">P\{\theta|D\} = \dfrac{P\{D|\theta\}P\{\theta\}}{P\{D\}}\tag{1.0}</script>其中$P{\theta|D}$称为后验概率，指的是由观察数据和先验假设推测出来的参数分布，而$P{\theta}$称之为先验分布，指的是对于参数的专家知识或者假设而引入的知识，可以指导参数$\theta$的学习，而$P{D|\theta}$称之为似然函数，指的就是由于观察数据导致的参数更新。</li></ul><hr><p>我们举个投硬币的例子也说明下这两者区别：</p><blockquote><p>Question：现在我们有一个硬币，假设朝向正面的几率为$p$，朝向反面的几率为$1-p$，这个$p$是未知的，现在为了估计$p$，投掷了14次，其中有10次朝向正面，问再投掷两次，都朝向正向的概率为多少。</p></blockquote><p>在传统的概率派解答中，因为相信这个模型的参数是固定的，所以很容易知道$p=\dfrac{10}{14}=0.714$，因此在后面投掷两次的过程中，假设都是独立过程，那么</p><script type="math/tex; mode=display">P\{HH|data\}=p^2=0.51\tag{1.1}</script><hr><p>而在贝叶斯派眼中，问题就没有那么简单了，我们相信参数$p$不是简单的一个参数，而应该是一个随机变量，服从一个分布，那么我们就需要用观察到了的数据$data$去估计这个参数$p$的分布，利用贝叶斯公式有：</p><script type="math/tex; mode=display">P\{p|data\} = \dfrac{P\{data|p\}P\{p\}}{P\{data\}}\tag{1.2}</script><p>因为在已知观察中，$data$是固定的，所以$P{data}=constant$是一个常数，不妨忽略它，有：</p><script type="math/tex; mode=display">P\{p|data\} \propto P\{data|p\}P\{p\}\tag{1.3}</script><p>有:</p><script type="math/tex; mode=display">P\{data|p\} = C_{14}^{10} p^{10}(1-p)^{4}\tag{1.4}</script><p>参数$C_{14}^{10}$可以忽略，现在对于先验假设$P{p}$进行假设，一般来说，我们希望这个假设是一个共轭先验（conjugate prior）<sup><a href="#fn_1" id="reffn_1">1</a></sup>。<br>这里用Beta分布作为硬币参数的先验假设，</p><script type="math/tex; mode=display">Beta(p;a,b)=\dfrac{\Gamma(a+b)}{\Gamma(a) \cdot \Gamma(b)} \cdot p^{a-1}(1-p)^{b-1}\tag{1.5}</script><p>其中伽马函数$\Gamma(\cdot)$定义为:</p><script type="math/tex; mode=display">\Gamma(x) = \int_{0}^{+\infty} t^{x-1}e^{-t} \rm dt\tag{1.6}</script><p>Beta分布有两个控制参数a和b，不同的a和b其CDF的形状差别很大：<br><img src="/imgs/basic/gamma.png" alt="gamma"></p><hr><p>在这个先验假设下，我们有：</p><script type="math/tex; mode=display">P\{p\} = Beta(p;a,b)\tag{1.7}</script><p>同样的，因为$\dfrac{\Gamma(a+b)}{\Gamma(a)}$是常数项，忽略所以有：</p><script type="math/tex; mode=display">\begin{align}P\{p|data\} &\propto p^{10}(1-p)^{4} \cdot p^{a-1} (1-p)^{b-1} \\& \propto p^{10+a-1}(1-p)^{4+b-1}\end{align}\tag{1.8}</script><p>为了让</p><script type="math/tex; mode=display">\int_{0}^{+\infty} p\{p|data\} \rm dp = 1\tag{1.9}</script><p>需要拼凑系数，可知道系数为（<strong>这里不是特别懂</strong>）</p><script type="math/tex; mode=display">\dfrac{\Gamma((10+a)+(4+b))}{\Gamma(10+a) \cdot \Gamma(4+b)} = \dfrac{1}{B(10+a,4+b)}\tag{1.10}</script><p>其中$B(x,y)$为Beta函数，$B(x,y) = \dfrac{\Gamma(x) \Gamma(y)}{\Gamma(x+y)}$</p><p>于是最终有参数$p$的概率分布为:</p><script type="math/tex; mode=display">P\{p|data\} = Beta(p;a+10, b+4)\tag{1.11}</script><p>如果我们对$p$毫无先验可言，那么可以令$a=b=0$，这个时候的计算结果就和频率学派的一模一样，但是如果我们自认为对这个硬币的参数$p$有所了解，但是又不是完全了解，比如说我们知道这个先验应该是一个均匀分布的（也就是正面和反面都应该是0.5的，这个应该是最朴素和直观的假设了。），而均匀分布是Beta分布的一个特例，我们可以令$a=b=1$，这个时候有：</p><script type="math/tex; mode=display">P\{p|data\} = Beta(p;11,5)\tag{1.12}</script><p>图像如：</p><p><img src="/imgs/basic/gamma_2.png" alt="gamma_2"></p><p>可以看到因为引入了这个朴素的假设，使得$p$变成了一个中心在$p=0.7$附近的钟形分布，这个时候就发现了和频率派的区别：<strong>我们的参数p是一个分布，而不只是一个数值而已。</strong></p><hr><p>有了$P{p|data}$，我们回归原问题，求:</p><script type="math/tex; mode=display">P\{HH|data\} = \int_{0}^{1} P\{HH|p\} P\{p|data\} \rm dp\tag{1.13}</script><p>这里用积分的原因很简单，就是因为我们的p是一个分布，其值从0到1，因此需要用积分。<br>这里进行两个假设：</p><ol><li>投掷硬币每一次都是独立无关的。</li><li>在这接下来的两个投掷过程中我们不更新$P{p|data}$</li></ol><p>所以有：</p><script type="math/tex; mode=display">P\{HH|p\} = [P\{H|p\}]^2 = p^2\tag{1.14}</script><p>所以有:</p><script type="math/tex; mode=display">P\{HH|data\} = \int_{0}^{1} p^2 \cdot P\{p|data\} \rm dp\tag{1.15}</script><p>所以有:</p><script type="math/tex; mode=display">\begin{align}P\{HH|data\} &= \dfrac{1}{B(10+a,4+b)} \int_{0}^{1} p^{(10+a-1)+2} (1-p)^{4+b-1} \\&= \dfrac{B(10+a+2,4+b)}{B(10+a, 4+b)}\end{align}\tag{1.16}</script><p>同样假设$a=b=1$则有$\dfrac{B(13,5)}{B(11, 5)}=0.485$，从这里就看出了频率学派和贝叶斯学派的区别。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>频率学派和贝叶斯学派的方法优缺点概况：</p><ul><li>频率学派是目前深度学习中最常使用的指导思想，但是要想其效果好，必须基于数据量巨大的情况下，否则很难估计出一个好的参数。（因为其不引入任何先验假设，只能从大数据中学习得到。）</li><li>贝叶斯学派的方法可以应用在数据量小的情况下，而且方便引入各种专家知识和先验知识，有些场景中表现更为优越。</li></ul><p>实际上，频率学派和贝叶斯学派有着千丝万缕的关系，不可割裂看待，也没有孰优孰劣。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Bishop 《Pattern Recognize and Machine Learning, PRML》</li><li><a href="http://www.behind-the-enemy-lines.com/2008/01/are-you-bayesian-or-frequentist-or.html" target="_blank" rel="noopener">《Are you a Bayesian or a Frequentist? (Or Bayesian Statistics 101)》</a></li><li><a href="https://stats.stackexchange.com/questions/22/bayesian-and-frequentist-reasoning-in-plain-english" target="_blank" rel="noopener">《Bayesian and frequentist reasoning in plain English》</a></li><li><a href="https://blog.csdn.net/baimafujinji/article/details/51374202">《先验概率、后验概率以及共轭先验》</a></li></ol><blockquote id="fn_1"><sup>1</sup>. 后验概率分布（正⽐于先验和似然函数的乘积）拥有与先验分布相同的函数形式。这个性质被叫做共轭性（Conjugacy）。共轭先验（conjugate prior）有着很重要的作⽤。它使得后验概率分布的函数形式与先验概率相同，因此使得贝叶斯分析得到了极⼤的简化<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;strong&gt;对于一个数学模型来说，最主要的莫过于根据观察到的数据进行模型的参数估计了，而概率学派和贝叶斯学派对于这个参数估计有着不同的做法，接下来我们讨论下。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;str
      
    
    </summary>
    
      <category term="Basic concept" scheme="https://blog.csdn.net/LoseInVain/categories/Basic-concept/"/>
    
    
      <category term="机器学习" scheme="https://blog.csdn.net/LoseInVain/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="概率学派" scheme="https://blog.csdn.net/LoseInVain/tags/%E6%A6%82%E7%8E%87%E5%AD%A6%E6%B4%BE/"/>
    
      <category term="贝叶斯学派" scheme="https://blog.csdn.net/LoseInVain/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow中的位操作</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/22/tensorflow/tf_bits/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/22/tensorflow/tf_bits/</id>
    <published>2018-10-22T07:04:56.409Z</published>
    <updated>2018-10-22T07:05:27.511Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br>版本号：1.10<br>TensorFlow支持位操作，在模块<a href="https://www.tensorflow.org/api_docs/python/tf/bitwise" target="_blank" rel="noopener"><code>tf.bitwise</code></a>中包含了几个基本的位操作，分别是：</p><ol><li><code>bitwise_and()</code>     位与操作 $c = a &amp; b$</li><li><code>bitwise_or()</code>       位或操作 $c = a | b$</li><li><code>bitwise_xor()</code>  位异或操作 $c = (~a &amp; b) | (a &amp; ~b)$</li><li><code>invert()</code>  位反操作 $c = ~a$</li><li><code>left_shift()</code>  位左移操作 $c = a &lt;&lt; b$</li><li><code>right_shift()</code> 位右移操作 $ c = a &gt;&gt; b$</li></ol><p>使用方法很简单，以<a href="https://www.tensorflow.org/api_docs/python/tf/bitwise/bitwise_and" target="_blank" rel="noopener">位与</a>为例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.bitwise.bitwise_and(</span><br><span class="line">    x,</span><br><span class="line">    y,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p>使用例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(<span class="number">8</span>)  <span class="comment"># 0000,1000</span></span><br><span class="line">b = tf.constant(<span class="number">4</span>)  <span class="comment"># 0000,0100</span></span><br><span class="line">bitor = tf.bitwise.bitwise_or(a,b)</span><br><span class="line">bitand = tf.bitwise.bitwise_and(a,b)</span><br><span class="line"><span class="keyword">with</span> tf.Session(config=config) <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(bitor))</span><br><span class="line">    print(sess.run(bitand))</span><br></pre></td></tr></table></figure></p><p>输出第一个为12，第二个为0，其他操作类似于此。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;版本号：1.10&lt;br&gt;TensorFlow支持位操作，在模块&lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/bitwise&quot; target=
      
    
    </summary>
    
      <category term="TensorFlow Basic API" scheme="https://blog.csdn.net/LoseInVain/categories/TensorFlow-Basic-API/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="https://blog.csdn.net/LoseInVain/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>scp指令用于主机之间的文件相互拷贝</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/22/linux_cmd/scp/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/22/linux_cmd/scp/</id>
    <published>2018-10-22T07:02:03.845Z</published>
    <updated>2018-10-22T07:02:59.642Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br><strong>scp</strong>，是secure copy的简称，是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。<br>其基本使用方法见<a href="http://www.runoob.com/linux/linux-comm-scp.html" target="_blank" rel="noopener">《Linux scp命令》</a>。这里纪录下平时在开发过程中遇到的用法，以为备忘。</p><hr><p><strong>应用背景</strong>：在我们实验室进行深度学习开发，实验室有一个公网ip，记为ipc，因为机房有若干服务器，因此在路由器上进行了端口映射，每个端口对应每个服务器，其中我们小组的服务器的端口号为A和B，如果现在需要从主机b的文件file传送到主机a中，可以在主机A中用下列命令，fetch文件b：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -P B user_name@ipc:/home/user_name/file a_dst_path</span><br></pre></td></tr></table></figure></p><p>其中<code>user_name@ipc:/home/user_name/file</code>为主机B的用户名和文件地址，通过指定端口B来进行端口映射的选择，<code>a_dst_path</code>是本机A的保存地址。如果拷贝的是文件夹，则加上<code>-r</code>即可。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;strong&gt;scp&lt;/strong&gt;，是secure copy的简称，是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。&lt;br&gt;其基本使用方法见&lt;a href=&quot;http://www.run
      
    
    </summary>
    
      <category term="常用linux指令" scheme="https://blog.csdn.net/LoseInVain/categories/%E5%B8%B8%E7%94%A8linux%E6%8C%87%E4%BB%A4/"/>
    
    
      <category term="linux" scheme="https://blog.csdn.net/LoseInVain/tags/linux/"/>
    
      <category term="shell" scheme="https://blog.csdn.net/LoseInVain/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>einsum的基础使用</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/22/tensorflow/tf.einsum/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/22/tensorflow/tf.einsum/</id>
    <published>2018-10-22T06:58:06.539Z</published>
    <updated>2018-10-22T07:01:27.994Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br><strong>einsum</strong>全称为Einstein summation convention，是一种求和的范式，在很多基于多维张量的张量运算库，如<strong>numpy</strong>,<strong>tensorflow</strong>,<strong>pytorch</strong>中都有所应用。einsum可以用一种很简单的，统一的方式去表示很多多维张量的运算。让我们以numpy中的einsum为例子，理解这种运算表达方式。</p><p>这里贴出numpy中的einsum的API：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.einsum(subscripts, *operands, out=<span class="keyword">None</span>, dtype=<span class="keyword">None</span>, order=<span class="string">'K'</span>, casting=<span class="string">'safe'</span>, optimize=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p><p>其中关键的参数有<code>subscripts</code>用于指定计算模式,<code>operands</code>用于指定操作数，我们给个例子，如果现在我们有两个矩阵<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">B = np.array([[<span class="number">9</span>,<span class="number">2</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">1</span>,<span class="number">7</span>],[<span class="number">5</span>,<span class="number">2</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">A -&gt; array([[1, 2, 3],</span></span><br><span class="line"><span class="string">           [1, 3, 4],</span></span><br><span class="line"><span class="string">           [2, 3, 4]])</span></span><br><span class="line"><span class="string">B -&gt; array([[9, 2, 4],</span></span><br><span class="line"><span class="string">           [1, 1, 7],</span></span><br><span class="line"><span class="string">           [5, 2, 4]])</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure></p><p>如果我们现在想实现一个运算，如下公式所述:</p><script type="math/tex; mode=display">s(j) = \sum_{i=0}^{2} A[i,j]*B[i,j]</script><p>我们利用einsum这种形式就能够很好的表达，如:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s = np.einsum(<span class="string">'ij,ij-&gt;j'</span>,A,B)</span><br></pre></td></tr></table></figure></p><p>其输出结果为<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([<span class="number">20</span>, <span class="number">13</span>, <span class="number">56</span>])</span><br></pre></td></tr></table></figure></p><p>其中的<code>subscripts</code>参数就很好地描述了上述公式描述的运算过程，我们这里可以细究下这个参数。这个参数由三大部分构成，<code>a,b-&gt;c</code>其中<code>a</code>和<code>b</code>是描述的输入张量的索引，如上面的<code>ij</code>表示A和B张量的<code>i</code>行<code>j</code>列。<code>c</code>表示的是输出的索引，如上文中的<code>j</code>。当你指定了输出的索引之后，就可以把这个索引看成是固定的值了，因为他将会是作为一个自变量参数存在的，而可以把其他的索引变量（输入的索引变量）看成是循环变量。这个方式可以实现很多复杂的矩阵运算，如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">60.</span>).reshape(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">b = np.arange(<span class="number">24.</span>).reshape(<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">np.einsum(<span class="string">'ijk,jil-&gt;kl'</span>, a, b)</span><br></pre></td></tr></table></figure></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1]. <a href="https://rockt.github.io/2018/04/30/einsum" target="_blank" rel="noopener">EINSUM IS ALL YOU NEED - EINSTEIN SUMMATION IN DEEP LEARNING</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;strong&gt;einsum&lt;/strong&gt;全称为Einstein summation convention，是一种求和的范式，在很多基于多维张量的张量运算库，如&lt;strong&gt;numpy&lt;/stron
      
    
    </summary>
    
      <category term="TensorFlow Basic API" scheme="https://blog.csdn.net/LoseInVain/categories/TensorFlow-Basic-API/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="https://blog.csdn.net/LoseInVain/tags/TensorFlow/"/>
    
      <category term="编程技巧" scheme="https://blog.csdn.net/LoseInVain/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow中的image预处理操作函数</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/22/tensorflow/tf_image_prepocess_api/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/22/tensorflow/tf_image_prepocess_api/</id>
    <published>2018-10-22T06:53:01.935Z</published>
    <updated>2018-10-22T07:08:25.030Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br>TensorFlow中有着一个<code>image</code>模块专门用于处理图片数据的预处理，里面定义了若干常见的图像预处理函数，让我们列举出来，介绍一下，API地为 <a href="https://www.tensorflow.org/api_docs/python/tf/image" target="_blank" rel="noopener">tf.image</a>.</p><hr><ol><li><code>tf.image.adjust_brightness(images, delta)</code> ：用于改变原图像的明亮度，也就是在原图像的基础上加上一个<code>delta</code>，于是我们有<code>new_image = old_image+delta</code>。</li><li><code>tf.image.adjust_contrast(images,contrast_factor)</code>：改变原图片的对比度，公式为$(x - mean) * contrast\_factor + mean$, 其中的<code>x</code>为原输入，<code>mean</code>为每个通道的均值。</li><li><code>tf.image.adjust_jpeg_quality(images, jpeg_quality)</code>：改变原jpeg图像的编码质量（不是很懂什么叫做编码质量，望指正），其中的<code>jpeg_quality</code>需在[0,100]这个区间内。</li><li><code>tf.image.adjust_gamma</code>：伽马矫正，$\rm{Out} = \rm{Input}^{gamma}$</li><li><code>tf.image.adjust_hue(image,delta)</code>：改变原图像的色彩(hue)，本函数将原RGB图像转换到HSV空间后，在hue通道上加上<code>delta</code>后，再转换回RGB空间。</li><li><code>tf.image.adjust_saturation(images,saturation_factor)</code>：类似于改变色彩的函数，这个函数改变的是饱和度。</li><li><code>tf.image.central_crop(images,central_fraction)</code>：对图像进行中心修剪，也就是按照一定比例保留中间的像素，去除中心之外的像素，注意输出图像和输入图像的尺寸是一样的，也就是说中心之外的像素置位了而已。其中<code>central_fraction</code>在[0,1]区间，表示的是中心保留的比例。</li><li><code>tf.image.convert_image_dtype(image,dtype,saturate=False)</code>：改变图片的数据类型，其中<code>dtype</code>是目标数据类型，注意到这个转换不是单纯的数据类型转换，他会将浮点类型的图片归一化到[0,1]之间，整型的数据类型归一化到[0,MAX]之间，这里的MAX指的是不同整型数据类型能够表达的最大正数。注意到在浮点型转换到整型的过程中可能会出现上溢或者下溢的问题，如果指定了<code>saturate=True</code>将可以避免这个问题，它会在数据类型转换之前截断输入的值，比如输入是1.02，那么就会截为1.0</li><li><code>tf.image.decode_bmp</code>,<code>tf.image.decode_gif</code>,<code>tf.image.decode_jpeg</code>,<code>tf.image.encode_png</code>，这些都是图片解码函数，传入图片的地址，解码出图片。可以用更为同一的接口<code>tf.image.decode_image</code>代替，它会自动判断图片的格式并且解码。</li></ol><hr><h1 id="编码和解码函数"><a href="#编码和解码函数" class="headerlink" title="编码和解码函数"></a>编码和解码函数</h1><p>TensorFlow提供了一些操作用于编码和解码JPEG，PNG格式的图片。编码后的图像用一个标量字符串张量(Scalar String Tensor，我觉得就是一个图片的地址吧)表示，解码后的图像用一个3D的uint8类型的张量表示，尺寸为<code>[height,width,channels]</code>。（PNG也可以支持uint16的数据类型）。<br>这些编解码操作在一个时刻只能应用于一张图片，他们的输入和输出都是可变长的，如果你需要固定尺寸的图片，那么就对输出结果进行裁剪或者resize吧。相关函数有：</p><ul><li><code>tf.image.decode_bmp</code></li><li><code>tf.image.decode_gif</code></li><li><code>tf.image.decode_jpeg</code></li><li><code>tf.image.encode_jpeg</code></li><li><code>tf.image.decode_png</code></li><li><code>tf.image.encode_png</code></li><li><code>tf.image.decode_image</code></li></ul><h1 id="resize操作"><a href="#resize操作" class="headerlink" title="resize操作"></a>resize操作</h1><p>resize操作用于将输入图像重新缩放或者放大到固定的尺寸，通常是在数据类型tf.float32情况下应用的。有个简便的函数<code>tf.image.resize_images</code>同时支持了4D和3D的张量作为输入并且输出。4D的张量指的是包括了batch，3D张量就仅仅是一张图片。其他的resize操作仅仅支持4D张量作为输入，如：</p><ul><li><code>tf.image.resize_area</code></li><li><code>tf.image.resize_bicubic</code> （双立方插值）</li><li><code>tf.image.resize_bilinear</code> （双线性插值）</li><li><code>tf.image.resize_nearest_neighbor</code> （最近邻插值）</li></ul><h1 id="裁剪Crop"><a href="#裁剪Crop" class="headerlink" title="裁剪Crop"></a>裁剪Crop</h1><p>有些场景中需要对原输入图像进行裁剪，可能是随机裁剪，也可是中心对齐裁剪，TF提供了一系列的裁剪函数：</p><ul><li><code>tf.image.resize_image_with_crop_or_pad</code></li><li><code>tf.image.central_crop</code></li><li><code>tf.image.pad_to_bounding_box</code></li><li><code>tf.image.crop_to_bounding_box</code></li><li><code>tf.image.extract_glimpse</code></li><li><code>tf.image.crop_and_resize</code></li></ul><h1 id="翻转，旋转和转置操作"><a href="#翻转，旋转和转置操作" class="headerlink" title="翻转，旋转和转置操作"></a>翻转，旋转和转置操作</h1><p>有些时候采取这些操作有利于数据的增广，增大训练集。这些函数输入都是4D张量。</p><ul><li><code>tf.image.flip_up_down</code> （向下翻转）</li><li><code>tf.image.random_flip_up_down</code>（随机上下翻转）</li><li><code>tf.image.flip_left_right</code>（向左右翻转）</li><li><code>tf.image.random_flip_left_right</code>（随机左右翻转）</li><li><code>tf.image.transpose_image</code>（图像转置，调换<code>width</code>和<code>height</code>轴）</li><li><code>tf.image.rot90</code>（顺时针方向旋转90°）</li></ul><h1 id="颜色空间变换"><a href="#颜色空间变换" class="headerlink" title="颜色空间变换"></a>颜色空间变换</h1><p>提供了RGB颜色空间到HSV颜色空间的转换函数，必须在float32的数据类型下进行，可以考虑用<code>tf.image.convert_image_dtype</code>对整型输入进行转换。</p><ul><li><code>tf.image.rgb_to_grayscale</code>（RGB到灰度图）</li><li><code>tf.image.grayscale_to_rgb</code>（灰度图到RGB，注意，并不是伪彩色，而是单纯复制了三个通道而已）</li><li><code>tf.image.hsv_to_rgb</code>（HSV到RGB）</li><li><code>tf.image.rgb_to_hsv</code>（RGB到HSV）</li><li><code>tf.image.convert_image_dtype</code>（转换图片的数据类型）</li></ul><h1 id="图片调整"><a href="#图片调整" class="headerlink" title="图片调整"></a>图片调整</h1><p>TF提供了一系列的函数用于调整图片的基本参数，如：明亮度，对比度，色彩，饱和度等。<strong>每个操作都需要在预先定义好的参数，或者随机的参数（从一个预定义的区间中随机取）中完成</strong>，随机调整有利于在训练集中提高泛化性能。</p><ul><li><code>tf.image.adjust_brightness</code>（调整明亮度）</li><li><code>tf.image.random_brightness</code>（随机明亮度）</li><li><code>tf.image.adjust_contrast</code>（调整对比度）</li><li><code>tf.image.random_contrast</code>（随机对比度）</li><li><code>tf.image.adjust_hue</code>（调整色彩）</li><li><code>tf.image.random_hue</code>（随机色彩）</li><li><code>tf.image.adjust_gamma</code>（gamma矫正）</li><li><code>tf.image.adjust_saturation</code>（调整饱和度）</li><li><code>tf.image.random_saturation</code>（随机饱和度）</li><li><code>tf.image.per_image_standardization</code>（图片标准化，零均值单位方差）</li></ul><h1 id="bounding-box相关"><a href="#bounding-box相关" class="headerlink" title="bounding box相关"></a>bounding box相关</h1><ul><li><code>tf.image.draw_bounding_boxes</code> （绘制bounding box）</li><li><code>tf.image.non_max_suppression</code> （非极大抑制）</li><li><code>tf.image.sample_distorted_bounding_box</code> </li></ul><h1 id="解噪"><a href="#解噪" class="headerlink" title="解噪"></a>解噪</h1><ul><li><code>tf.image.total_variation</code> （计算图片总方差）</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;TensorFlow中有着一个&lt;code&gt;image&lt;/code&gt;模块专门用于处理图片数据的预处理，里面定义了若干常见的图像预处理函数，让我们列举出来，介绍一下，API地为 &lt;a href=&quot;https:
      
    
    </summary>
    
      <category term="TensorFlow Basic API" scheme="https://blog.csdn.net/LoseInVain/categories/TensorFlow-Basic-API/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="https://blog.csdn.net/LoseInVain/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow编程实践：结构化你的模型</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/22/tensorflow/structure_your_model/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/22/tensorflow/structure_your_model/</id>
    <published>2018-10-22T06:50:35.233Z</published>
    <updated>2018-10-22T06:57:03.946Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br>这篇文章是翻译自<a href="https://danijar.com/structuring-your-tensorflow-models/" target="_blank" rel="noopener">《Structuring Your TensorFlow Models》</a>，这篇文章主要描述了在TensorFlow中如何更好地结构化地定义你的网络模型，以便于更好地扩展和调试。我们将会发现，采用这种构建方法，可以将整个模型变得模块化。<br>如果对这篇文章有着更好的建议，请联系我，谢谢。</p><hr><p>在TensorFlow中定义你的模型很容易导致一个臃肿复杂，难以维护的代码，这个是一个很糟糕的事情，因为深度模型本身就难以调试和差错，因此在模型的搭建过程中应该尽可能的用模块化的方法去搭建模型和结构化模型。如何以一种高可读性和可复用性的手段结构化你的代码呢？如果你急于求成，可以直接参考<a href="https://gist.github.com/danijar/8663d3bbfd586bffecf6a0094cd116f2" target="_blank" rel="noopener">working example gist</a>。也可以参考这篇关于如何在TensorFlow中实现快速原型的文章<a href="https://danijar.com/patterns-for-fast-prototyping-with-tensorflow/" target="_blank" rel="noopener">fast prototyping</a>，结构化模型的基本思想就在这里描述了。</p><h1 id="定义计算图"><a href="#定义计算图" class="headerlink" title="定义计算图"></a>定义计算图</h1><p>给每一个模型定义一个类是很科学而且高效的做法。那么，用什么作为这个类的接口呢？通常来说，你的模型会和一些<strong>输入数据</strong>和<strong>目标数据(target)</strong>的<strong>占位符(placeholder)</strong>存在关联，毕竟你需要以此来喂(feed)数据，并且提供一个接口给主程序训练(training)，评估(evaluation)和推理(inference)。也就是说，我们这个类，至少要提供这几种接口才是一个较为完整的深度网络模型类：</p><ul><li>喂数据的接口， 如输入和目标的占位符等。</li><li>提供给主程序调用的训练，评估和推理接口</li><li>（可选）一个网络中间输出结果，这种用法类似与pytorch和keras的做法，把一些成熟的网络模块化后直接输出中间处理结果，以便于更好的模块化。</li></ul><p>我们观察一下例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data, target)</span>:</span></span><br><span class="line">        data_size = int(data.get_shape()[<span class="number">1</span>])</span><br><span class="line">        target_size = int(target.get_shape()[<span class="number">1</span>])</span><br><span class="line">        weight = tf.Variable(tf.truncated_normal([data_size, target_size]))</span><br><span class="line">        bias = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[target_size]))</span><br><span class="line">        incoming = tf.matmul(data, weight) + bias</span><br><span class="line">        self._prediction = tf.nn.softmax(incoming)</span><br><span class="line">        cross_entropy = -tf.reduce_sum(target, tf.log(self._prediction))</span><br><span class="line">        self._optimize = tf.train.RMSPropOptimizer(<span class="number">0.03</span>).minimize(cross_entropy)</span><br><span class="line">        mistakes = tf.not_equal(</span><br><span class="line">            tf.argmax(target, <span class="number">1</span>), tf.argmax(self._prediction, <span class="number">1</span>))</span><br><span class="line">        self._error = tf.reduce_mean(tf.cast(mistakes, tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">prediction</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._prediction</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">optimize</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._optimize</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">error</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._error</span><br></pre></td></tr></table></figure></p><p>这是一个基本的关于如何在TF中定义模型的代码，然而，这个代码还是存在一些问题的。最明显的问题是，这整个模型的计算图都定义在了一个函数里面，也就是构造器。如果你的模型变得很复杂，这个构造器将变得异常臃肿，这样既不是可读性强的，也不是可复用性强的编程习惯。（<strong>译者：而且，这里还有一个问题，如果按照以上的代码去进行整个模型的图的构建，那么不管我们是不是需要用到整个模型的每个子模型，他都会给我一股脑地预先构建出来。这样其实不是一个很好的方案，因为很多时候，模型很大，有很多分支，而且训练阶段也有不止一个阶段，每个阶段可能用到不同的分支。因此并没有必要一股脑把所有分支给构建出来，用本文的思路可以实现很好的结构化模型。</strong>）</p><h1 id="利用类属性-Properties-去结构化你的模型吧"><a href="#利用类属性-Properties-去结构化你的模型吧" class="headerlink" title="利用类属性(Properties)去结构化你的模型吧"></a>利用类属性(Properties)去结构化你的模型吧</h1><p>简单地将你的构建计算图的代码从构造器中分离出来不能解决任何问题，因为每一次这个函数被调用的时候，这个计算图都会添加新的节点。这并不是我们想要的，我们需要的是这个计算图只会在我们<strong>第一次</strong>调用某个模块的构建的时候在整个计算图中添加新的节点，在第二次或者更多次的时候，不需要其再次添加相同的节点，这个被称之为<strong>惰性加载(lazy-loading)</strong>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data, target)</span>:</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.target = target</span><br><span class="line">        self._prediction = <span class="keyword">None</span></span><br><span class="line">        self._optimize = <span class="keyword">None</span></span><br><span class="line">        self._error = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">prediction</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._prediction:</span><br><span class="line">            data_size = int(self.data.get_shape()[<span class="number">1</span>])</span><br><span class="line">            target_size = int(self.target.get_shape()[<span class="number">1</span>])</span><br><span class="line">            weight = tf.Variable(tf.truncated_normal([data_size, target_size]))</span><br><span class="line">            bias = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[target_size]))</span><br><span class="line">            incoming = tf.matmul(self.data, weight) + bias</span><br><span class="line">            self._prediction = tf.nn.softmax(incoming)</span><br><span class="line">        <span class="keyword">return</span> self._prediction</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">optimize</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._optimize:</span><br><span class="line">            cross_entropy = -tf.reduce_sum(self.target, tf.log(self.prediction))</span><br><span class="line">            optimizer = tf.train.RMSPropOptimizer(<span class="number">0.03</span>)</span><br><span class="line">            self._optimize = optimizer.minimize(cross_entropy)</span><br><span class="line">        <span class="keyword">return</span> self._optimize</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">error</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._error:</span><br><span class="line">            mistakes = tf.not_equal(</span><br><span class="line">                tf.argmax(self.target, <span class="number">1</span>), tf.argmax(self.prediction, <span class="number">1</span>))</span><br><span class="line">            self._error = tf.reduce_mean(tf.cast(mistakes, tf.float32))</span><br><span class="line">        <span class="keyword">return</span> self._error</span><br></pre></td></tr></table></figure></p><p>这个比第一个例子好多了，你的代码现在可以在类中的方法中结构化，因此你只需要单独地关注某个部分就可以了。然而，这个代码为了实现这个惰性加载的逻辑，额外多出了很多判断的分子，这个仍然是有些臃肿的，我们利用python中自带的修饰器的性质，可以进行一些修改。</p><h1 id="惰性类属性修饰器"><a href="#惰性类属性修饰器" class="headerlink" title="惰性类属性修饰器"></a>惰性类属性修饰器</h1><p>python是一种很灵活的语言，在下一个例子中，我将展示给你如何从上一个例子的代码中除去冗余的代码。我们将会使用一个<strong>表现得像是<code>@property</code></strong>但是<strong>只会实际上调用这个函数一次</strong>的修饰器。如果你对如何定制修饰器不熟悉，也许你可以先参考这篇文章<a href="https://blog.csdn.net/LoseInVain/article/details/82055524">python修饰器教程</a>。采用这种方法，可以有效地减少一些为了实现惰性加载的逻辑而额外多出的代码，如<code>if not self._error:</code>这一部分。我们观察一下我们需要的修饰器代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lazy_property</span><span class="params">(function)</span>:</span></span><br><span class="line">    attribute = <span class="string">'_cache_'</span> + function.__name__</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line"><span class="meta">    @functools.wraps(function)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decorator</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, attribute):</span><br><span class="line">            setattr(self, attribute, function(self))</span><br><span class="line">        <span class="keyword">return</span> getattr(self, attribute)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> decorator</span><br></pre></td></tr></table></figure></p><p>采用这个修饰器，我们的例子可以被简化为下面的代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data, target)</span>:</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.target = target</span><br><span class="line">        self.prediction</span><br><span class="line">        self.optimize</span><br><span class="line">        self.error</span><br><span class="line"></span><br><span class="line"><span class="meta">    @lazy_property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">prediction</span><span class="params">(self)</span>:</span></span><br><span class="line">        data_size = int(self.data.get_shape()[<span class="number">1</span>])</span><br><span class="line">        target_size = int(self.target.get_shape()[<span class="number">1</span>])</span><br><span class="line">        weight = tf.Variable(tf.truncated_normal([data_size, target_size]))</span><br><span class="line">        bias = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[target_size]))</span><br><span class="line">        incoming = tf.matmul(self.data, weight) + bias</span><br><span class="line">        <span class="keyword">return</span> tf.nn.softmax(incoming)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @lazy_property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">optimize</span><span class="params">(self)</span>:</span></span><br><span class="line">        cross_entropy = -tf.reduce_sum(self.target, tf.log(self.prediction))</span><br><span class="line">        optimizer = tf.train.RMSPropOptimizer(<span class="number">0.03</span>)</span><br><span class="line">        <span class="keyword">return</span> optimizer.minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @lazy_property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">error</span><span class="params">(self)</span>:</span></span><br><span class="line">        mistakes = tf.not_equal(</span><br><span class="line">            tf.argmax(self.target, <span class="number">1</span>), tf.argmax(self.prediction, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> tf.reduce_mean(tf.cast(mistakes, tf.float32))</span><br></pre></td></tr></table></figure></p><p>注意到我们在关于图构建的函数中都是用了这个修饰器的。需要另外注意的是，当你运行<code>tf.initialize_variables()</code>以初始化变量的时候，务必留意你是否已经定义了这个计算图，否则是会报错的。</p><h1 id="更进一步，用名字空间-Scopes-组织计算图"><a href="#更进一步，用名字空间-Scopes-组织计算图" class="headerlink" title="更进一步，用名字空间(Scopes)组织计算图"></a>更进一步，用名字空间(Scopes)组织计算图</h1><p>我们现在有了一个更为简洁干净的方法去定义我们的模型，但是这个计算图仍然还是太过于拥挤了，如果你曾经用<code>tensorboard</code>可视化过整个计算图，你肯定明白我说的是什么意思，整个计算图将会包括很多小节点之间的互连。解决这个问题可以通过用一个“包裹”把这些互连的内容给打包起来，通过利用<code>tf.name_scope()</code>或者<code>tf.variable_scope()</code>你就可以实现这个功能，这两者的具体区别我们以后再谈，姑且看下这两个函数怎么使用。在计算图中，你可以指定某些节点被聚合在一起。我们而且，可以让我们的修饰器自动地实现这个功能，而不需要每个都人工手动完成。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">define_scope</span><span class="params">(function)</span>:</span></span><br><span class="line">    attribute = <span class="string">'_cache_'</span> + function.__name__</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line"><span class="meta">    @functools.wraps(function)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decorator</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, attribute):</span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(function.__name):</span><br><span class="line">                setattr(self, attribute, function(self))</span><br><span class="line">        <span class="keyword">return</span> getattr(self, attribute)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> decorator</span><br></pre></td></tr></table></figure></p><p>因为每个模块都是有功能性的特异性的，因此给每个模块一个新的名字。除此之外，这个模型和之前那个完全一样。<br>我们甚至可以走得更远一点，我们可以让<code>@define_scope</code>修饰器可以传递参数给<code>tf.variable_scope()</code>，比如说给定义一个默认的初始化之类的。如果你对这方面的感兴趣，请移步<a href="https://gist.github.com/danijar/8663d3bbfd586bffecf6a0094cd116f2" target="_blank" rel="noopener">blog_tensorflow_scope_decorator.py</a>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;这篇文章是翻译自&lt;a href=&quot;https://danijar.com/structuring-your-tensorflow-models/&quot; target=&quot;_blank&quot; rel=&quot;noopene
      
    
    </summary>
    
      <category term="TensorFlow Practice" scheme="https://blog.csdn.net/LoseInVain/categories/TensorFlow-Practice/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="https://blog.csdn.net/LoseInVain/tags/TensorFlow/"/>
    
      <category term="结构化模型" scheme="https://blog.csdn.net/LoseInVain/tags/%E7%BB%93%E6%9E%84%E5%8C%96%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="编程技巧" scheme="https://blog.csdn.net/LoseInVain/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>生成模型和判别模型的区别</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/22/basic/generative_discriminative_model/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/22/basic/generative_discriminative_model/</id>
    <published>2018-10-22T06:41:45.600Z</published>
    <updated>2018-10-22T06:42:57.813Z</updated>
    
    <content type="html"><![CDATA[<font size="6"><b>前言</b></font> <p><strong> 机器学习中有两种大类的模型，分别是生成模型和判别模型，其分别代表了不同的预测思想，我们这里讨论一下两者的异同。</strong><br><strong>如有谬误，请联系指正。转载请注明出处。</strong></p><p><em>联系方式：</em><br><strong>e-mail</strong>: <code>FesianXu@163.com</code><br><strong>QQ</strong>: <code>973926198</code><br><strong>github</strong>: <code>https://github.com/FesianXu</code></p><hr><h1 id="机器学习的目标"><a href="#机器学习的目标" class="headerlink" title="机器学习的目标"></a>机器学习的目标</h1><p>首先，我们先要讨论整个机器学习的目标，在应用中最常见到的<strong>分类问题</strong>中，我们需要根据现有样本$x_i \in R^n$预测出其标签$y_i \in { 0,1,\dots,m}$，因此我们可以选择学习出<strong>条件概率</strong>$P(y_i|x_i), x_i \in R^n, y_i \in {0,1,\dots.m}$，如<strong>softmax分类器</strong>，<strong>logistic回归</strong>，亦是或者学习出样本特征$x_i$到标签$y_i$的直接映射（比起前者没有概率，而是直接的一个结果），如<strong>感知器Perceptron</strong>，<strong>SVM支持向量机</strong>。学习出了条件概率或者是其映射之后，我们就可以根据其样本特征$x_i$预测其标签了$y_i$。</p><hr><h1 id="生成模型-or-判别模型"><a href="#生成模型-or-判别模型" class="headerlink" title="生成模型 or 判别模型"></a>生成模型 or 判别模型</h1><p>这里，我们直接给出两者的定义：</p><p><strong>判别模型</strong>： 模型直接学习出条件概率$P(y_i|x_i)$，模型包括<strong>kNN，感知机，决策树，逻辑回归，最大熵模型，SVM，提升方法，条件随机场，神经网络，···</strong></p><p><strong>生成模型</strong>： 模型学习出联合概率分布$P(x,y)$，然后根据贝叶斯公式，得出条件概率分布$P(y|x) = \frac{P(x,y)}{\sum_iP(x,y_i)}$，模型包括<strong>朴素贝叶斯法、隐马尔科夫模型、混合高斯模型、AODE、Latent Dirichlet allocation（unsup）、Restricted Boltzmann Machine，···</strong></p><hr><p>于是，两者的区别就是是否需要学习出联合概率分布$P(x,y)$。<br>我们这里举一个维基百科里面的例子：</p><p>假如我们现在有四个样本：$(x,y)={(0,0), (0,0), (1,0), (1,1)}$</p><p>在判别模型眼中：<br>$P(Y|X)$</p><div class="table-container"><table><thead><tr><th></th><th style="text-align:center">y=0</th><th style="text-align:center">y=1</th></tr></thead><tbody><tr><td>x=0</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr><tr><td>x=1</td><td style="text-align:center">1/2</td><td style="text-align:center">1/2</td></tr></tbody></table></div><p>而在生成模型眼中：$P(X,Y)$</p><div class="table-container"><table><thead><tr><th></th><th style="text-align:center">y=0</th><th style="text-align:center">y=1</th></tr></thead><tbody><tr><td>x=0</td><td style="text-align:center">1/2</td><td style="text-align:center">0</td></tr><tr><td>x=1</td><td style="text-align:center">1/4</td><td style="text-align:center">1/4</td></tr></tbody></table></div><p>而在博客<a href="http://www.cnblogs.com/nolonely/p/6435213.html" target="_blank" rel="noopener">《机器学习之判别式模型和生成式模型》</a>中，举了一个很好的例子描述这两者的区别，这里引用如下：</p><blockquote><p><strong>判别模型</strong>：要确定一个羊是山羊还是绵羊，用判别模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。</p><p><strong>生成模型</strong>：利用生成模型是根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率是多少，在放到绵羊模型中看概率是多少，哪个大就是哪个。</p></blockquote><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://en.wikipedia.org/wiki/Generative_model" target="_blank" rel="noopener">Generative Model Wikipedia</a></li><li><a href="https://www.zhihu.com/question/20446337" target="_blank" rel="noopener">知乎， 机器学习“判定模型”和“生成模型‘有什么区别？</a></li><li><a href="http://www.cnblogs.com/nolonely/p/6435213.html" target="_blank" rel="noopener">机器学习之判别式模型和生成式模型</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt; 

&lt;p&gt;&lt;strong&gt; 机器学习中有两种大类的模型，分别是生成模型和判别模型，其分别代表了不同的预测思想，我们这里讨论一下两者的异同。&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;如有谬误，请联系指正。转载请注明出处
      
    
    </summary>
    
      <category term="Basic concept" scheme="https://blog.csdn.net/LoseInVain/categories/Basic-concept/"/>
    
    
      <category term="生成模型" scheme="https://blog.csdn.net/LoseInVain/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="判别模型" scheme="https://blog.csdn.net/LoseInVain/tags/%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="机器学习" scheme="https://blog.csdn.net/LoseInVain/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>《贝叶斯之旅》第四讲，曲线拟合问题与L2正则</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/22/bayesian/curve_fitting/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/22/bayesian/curve_fitting/</id>
    <published>2018-10-22T00:03:03.657Z</published>
    <updated>2018-10-22T00:09:53.238Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br><strong>我们在[1]中曾经谈到了在贝叶斯理论下指导的曲线拟合问题以及基于此的L2正则化解释，其实，对于L2正则化还可以从模型复杂度的角度进行解释，现在，我们针对非贝叶斯观点的曲线拟合问题和L2正则进行讨论。</strong></p><p><strong>如有谬误，请联系指正。转载请注明出处。</strong></p><p><em>联系方式：</em><br><strong>e-mail</strong>: <code>FesianXu@163.com</code><br><strong>QQ</strong>: <code>973926198</code><br><strong>github</strong>: <code>https://github.com/FesianXu</code></p><hr><h1 id="曲线拟合"><a href="#曲线拟合" class="headerlink" title="曲线拟合"></a>曲线拟合</h1><p>回想[1]我们谈到的多项式曲线拟合问题，我们这里重新描述一遍：<br>假设我们有一个训练集，其中有N个观察值，其自变量x写作$\mathbf{x} \equiv (x_1,\cdots,x_N)^T$，同时，对应的观察因变量值y写作$\mathbf{t} \equiv (t_1,\cdots,t_N)^T$。如下图是一组生成的数据，绿线为通过函数$f(x)$生成的，真实的生成曲线，蓝点是从绿线上取值后添加上噪声数据得到的。（这里的噪声可能来自于随机过程中的噪声，也可能是因为存在一些相关的变量没有被观察到）<br><img src="/imgs/bayesian/curve_g.png" alt="curve_g"><br>我们的目标，就是利用训练集来训练一个模型，对于一个新的$\hat{x}$输入，可以预测出其$\hat{t}$。这个过程中，将会隐式地学习到用来生成这个绿色曲线的$f(x)$。如果我们不考虑我们预测的不确定性，那么我们直接就可以采用最小化误差函数的方法进行模型参数值估计。我们假设模型为多项式模型，如下所示：</p><script type="math/tex; mode=display">y(x,\mathbf{w})=w_0+w_1x+w_2x^2+\cdots+w_Mx^M =\sum_{j=0}^M w_jx^j\tag{1.1}</script><p>注意到，这个模型是关于$\mathbf{w}$的线性模型，但是并不是关于$x$的线性模型，像这种多项式，关于未知参数呈现线性的模型统称为<strong>线性模型(Linear Model)</strong>。<br>为了让我们的模型尽可能的接近训练集的数据，我们引入一个所谓的<strong>误差函数(error function)</strong>去度量预测值和真实值之间的距离，一般我们可以采用<strong>平方和函数</strong>作为误差函数，从[1]中，我们将会发现，当数据噪声满足0均值高斯分布时，可以推出平方和损失函数。</p><script type="math/tex; mode=display">E(\mathbf{w}) = \frac{1}{2}\sum_{n=1}^N \{y(x_n,\mathbf{w})-t_n\}^2\tag{1.2}</script><p>下图展示了计算预测值和真实值之间的距离示意图，绿色距离之和即为所求。<br><img src="/imgs/bayesian/error.png" alt="error"></p><p>因为式子(1.2)是一个关于$\mathbf{w}$的二次函数，关于这些系数的导数将会是一个关于$\mathbf{w}$线性的，通过令其梯度的每一个分量的导数为0，我们可以知道其有一个唯一解$\mathbf{w}^*$，这个可以完全通过闭式解得到。当然也可以通过基于梯度下降的方法得到近似解[3]。</p><h1 id="模型复杂度"><a href="#模型复杂度" class="headerlink" title="模型复杂度"></a>模型复杂度</h1><p>接下来的问题就在于如何选取超参数$M$。如下图所示，M太大，将会导致模型复杂度太大，使得模型容易过拟合[4]；然而，如果M太小，则模型的复杂度太低，拟合能力差，导致欠拟合。<br><img src="/imgs/bayesian/polyM.png" alt="polyM"><br>但是，我们需要注意的是，导致模型过拟合和欠拟合的，不仅仅和超参数的设置有关，而且很重要的一点是：<strong>和你训练集的好坏，规模也有重要的关系</strong>。如下图所示，左图是$N=15$个样本点，而右图是$N=100$个样本点，同样地采用了$M=9$的超参数设置，我们可以明显地看到，样本数量更多的一个，越符合真实的数据生成函数。<strong>不失一般地说，模型容量越大，模型复杂度越高，就需要更多的数据进行训练，以排除噪声的影响。</strong></p><p><img src="/imgs/bayesian/dataset_relevant.png" alt="dataset_relevant"><br>我们再次回到$M=0,1,6,9$的四种情况，我们分别观察它的$\mathbf{w}^*$系数，我们有：<br><img src="/imgs/bayesian/params.png" alt="params"></p><p>不难发现，M越大，其参数$w_i^*$的幅度也越大，并且是正负交错的，这使得拟合曲线有着极大的震荡，能够在训练集上精确地拟合每一个训练数值，导致其泛化性能极差。在[1]中我们将会对$\mathbf{w}$进行一个先验假设，通过贝叶斯理论的方法减缓这种情况的发生。<br>然而，现在我们可以同样完成这一件事情，通过添加一个<strong>惩罚项(penalty)</strong>即可，我们称之为<strong>正则项(regularization)</strong>。形式如：</p><script type="math/tex; mode=display">\tilde{E}(\mathbf{w}) = \frac{1}{2}\sum_{n=1}^N\{y(x_n,\mathbf{w})-t_n\}^2+\frac{\lambda}{2}\mathbf{w}^T\mathbf{w}</script><p>其中的惩罚项(正则项)$\mathbf{w}^T\mathbf{w}=||\mathbf{w}||^2=w_0^2+\cdots+w_M^2$，然后$\lambda$调节其和平方和损失之间的重要性比例。这种正则称之为L2正则化，因为求模操作也被称之为L2范式的原因。通过引入这种正则操作，使得参数能够尽可能的小，而不会导致上面谈到的问题。这种二次正则子称为<strong>岭回归(ridge regression)</strong>，在神经网络相关文献中，也称之为<strong>权值衰减(weight decay)</strong>（注意和学习率指数衰减分开）。</p><hr><p>参考我们在[4]中曾经讨论过的，我们一般有两种方式限制模型容量，通过设置超参数进而控制模型的假设空间太困难了，比如这里的$M$的选取就是一个困难的事。因此我们往往采取第二种做法，添加正则项对模型进行偏好排除，我们设置一个足够大的$M$，当然也不能太大，但是起码不用担心其不够容量对数据进行拟合即可，然后添加合适的正则项进行模型的偏好排除就可以较为容易地控制模型容量。这个方法也是在深度学习中经常使用的。</p><p>最后我们定量地观察下正则项前系数$\lambda$对参数$w_i^*$的影响，如下图所示,当$\lambda \rightarrow 1$的时候，可以观察到参数的确都缩小到了合适的范围。</p><p><img src="/imgs/bayesian/lambda.png" alt="lambda"></p><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] <a href="https://blog.csdn.net/LoseInVain/article/details/82822631">《贝叶斯曲线拟合以及对L2正则化的贝叶斯解释》</a><br>[2] Bishop C M. Pattern recognition and machine learning (information science and statistics) springer-verlag new york[J]. Inc. Secaucus, NJ, USA, 2006.<br>[3] <a href="https://blog.csdn.net/LoseInVain/article/details/78243051">随机梯度下降法，批量梯度下降法和小批量梯度下降法以及代码实现</a><br>[4] <a href="https://blog.csdn.net/LoseInVain/article/details/78108990">机器学习模型的容量，过拟合与欠拟合</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;strong&gt;我们在[1]中曾经谈到了在贝叶斯理论下指导的曲线拟合问题以及基于此的L2正则化解释，其实，对于L2正则化还可以从模型复杂度的角度进行解释，现在，我们针对非贝叶斯观点的曲线拟合问题和L2正则
      
    
    </summary>
    
      <category term="Bayesian Theory" scheme="https://blog.csdn.net/LoseInVain/categories/Bayesian-Theory/"/>
    
    
      <category term="贝叶斯理论" scheme="https://blog.csdn.net/LoseInVain/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/"/>
    
      <category term="统计学习方法" scheme="https://blog.csdn.net/LoseInVain/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
      <category term="L2正则" scheme="https://blog.csdn.net/LoseInVain/tags/L2%E6%AD%A3%E5%88%99/"/>
    
      <category term="曲线拟合" scheme="https://blog.csdn.net/LoseInVain/tags/%E6%9B%B2%E7%BA%BF%E6%8B%9F%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>《贝叶斯之旅》第三讲，贝叶斯曲线拟合以及对L2正则化的贝叶斯解释</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/22/bayesian/bayesian_curve_fitting/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/22/bayesian/bayesian_curve_fitting/</id>
    <published>2018-10-21T23:49:49.053Z</published>
    <updated>2018-10-21T23:53:57.739Z</updated>
    
    <content type="html"><![CDATA[<font size="6"><b>前言</b></font> <p><strong>在以前文章中，我们讨论过<a href="https://blog.csdn.net/loseinvain/article/details/80499147">《概率学派和贝叶斯学派的区别》</a>和<a href="https://blog.csdn.net/loseinvain/article/details/78245665">《 &lt;机器学习系列&gt; 线性回归模型》</a>，这里我们讨论下曲线拟合问题中的数据点的噪声问题，以及根据贝叶斯理论的L2正则化解释。</strong></p><p><strong>如有谬误，请联系指正。转载请注明出处。</strong></p><p><em>联系方式：</em><br><strong>e-mail</strong>: <code>FesianXu@163.com</code><br><strong>QQ</strong>: <code>973926198</code><br><strong>github</strong>: <code>https://github.com/FesianXu</code></p><hr><h1 id="曲线拟合问题"><a href="#曲线拟合问题" class="headerlink" title="曲线拟合问题"></a>曲线拟合问题</h1><p>这里的曲线指的是多项式曲线（polynomial curve）<sup><a href="#fn_1" id="reffn_1">1</a></sup>，如下图所示：</p><p><img src="/imgs/bayesian/poly_curve.png" alt="poly_curve"></p><p>一般来说，概率学派按照最小化平方和误差函数，如下所示，来进行参数的学习的。</p><script type="math/tex; mode=display">\mathcal{T}_{\theta} = \arg \min_{\theta} \mathcal{L}(\hat{y},y) \\\hat{y}_j = \sum_{i=0}^N \theta_i x_{(i,j)}^{i} = y(x;\theta)\\\mathcal{L}(\hat{y}, y) = \dfrac{1}{2}||\hat{y}-y||^2\tag{1.1}</script><p>$x_{(i,j)}$表示第$j$个样本的第$i$维数据值。更新策略采用梯度下降法[4]即可更新参数，达到收敛。</p><hr><h1 id="用概率角度看待曲线拟合，考虑下噪声吧"><a href="#用概率角度看待曲线拟合，考虑下噪声吧" class="headerlink" title="用概率角度看待曲线拟合，考虑下噪声吧~"></a>用概率角度看待曲线拟合，考虑下噪声吧~</h1><p>但是按照上面策略进行曲线拟合是没有考虑到数据的不确定性（uncertainty）的，这种不确定性体现在数据是添加了噪声的，而基于直接估计出一个点，然后直接拟合的方式没有考虑到这种噪声。为了描述这种不确定性，我们接下来以一种概率的角度去看待曲线拟合问题。</p><p>假设我们通过多项式模型预测出来的并不是一个单纯的数字，而是一个分布，一般来说我们将其假设为是一个均值为$t$（也就是预测目标值），方差为$\sigma^2$（$\beta=\dfrac{1}{\sigma^2}$，$\beta$称之为精确度precision），因此预测出来的分布如下式所示：</p><script type="math/tex; mode=display">p(t|x, \textbf{w}, \beta) = \mathcal{N} (t|y(x, \textbf{w}), \beta^{-1})\tag{1.2}</script><p>我们之所以假设为是高斯分布，是因为<strong>我们假设数据添加的噪声是高斯噪声</strong>，既是：</p><script type="math/tex; mode=display">\mathbf{x}_{\rm{observe}} = \mathbf{x}_{\rm{real}}+\mathcal{N}(\mu,\sigma^2)\tag{1.3 数据的噪声分解模型}</script><p>图像看起就更加直观了：</p><p><img src="/imgs/bayesian/bayesian.png" alt="bayesian"></p><p>可以看出，对于某一个预测，其为一个分布（蓝色线），其中预测的均值的预期就是观察值点A，可以看出，参数$\beta$决定了其置信范围$2\sigma$的大小。这个$2\sigma$的范围可以认为是认为假设的，噪声的主要范围。</p><p>如果采用频率学派中的观点，那么就会采用<strong>极大似然法</strong>进行参数估计。似然函数如下所示：</p><script type="math/tex; mode=display">p(\textbf{t}|\textbf{x},\textbf{w}, \beta) = \prod_{i=0}^N \mathcal{N} (t_n | y(x_n, \textbf{w}), \beta^{-1})\tag{1.4}</script><p>为了计算方便转化为对数似然后，有：</p><script type="math/tex; mode=display">\mathcal{L} = \ln p(\textbf{t}|\textbf{x},\textbf{w}, \beta) \\   = -\dfrac{\beta}{2} \sum_{n=1}^N \{y(x_n, \textbf{w})-t_n\}^2 + \dfrac{N}{2}\ln \beta - \dfrac{N}{2} \ln (2\pi)\tag{1.5}</script><p>为了估计出$\mathbf{w}$，我们用$\mathcal{L}$对$\mathbf{w}$求偏导数，并且令其为0。我们可以发现(1.5)中的后两项和$\mathbf{w}$并没有关系，因此可以舍弃。同时，因为$\beta$的取值并不会影响$\mathbf{w}$的极值点，因此可以令其为$\beta=1$。最终，我们有：</p><script type="math/tex; mode=display">\mathcal{L}   = -\dfrac{1}{2} \sum_{n=1}^N \{y(x_n, \textbf{w})-t_n\}^2 \\\mathcal{T} = \max_{\mathbf{w}} \mathcal{L} = \min_{\mathbf{w}} \mathcal{-L}\tag{1.6}</script><p>不难发现，其实(1.6)式子就是<strong>平方和损失</strong>，因此我们得出结论：<br>$\nabla$<strong>平方和损失，是在假设数据噪声符合0均值高斯分布的情况下推导出的。</strong>$\nabla$</p><p>当然，这里的精度$\beta$也可以用最大似然法估计，有：</p><script type="math/tex; mode=display">\frac{1}{\hat{\beta}} = \frac{1}{N} \sum_{n=1}^N \{y(x_n,\hat{\mathbf{w})}-t_n\}^2\tag{1.7}</script><p>其中的$\hat{\mathbf{w}}$是对权值的估计。</p><hr><h1 id="对参数引入先验假设，向着贝叶斯的更进一步"><a href="#对参数引入先验假设，向着贝叶斯的更进一步" class="headerlink" title="对参数引入先验假设，向着贝叶斯的更进一步"></a>对参数引入先验假设，向着贝叶斯的更进一步</h1><p>注意到我们之前讨论的都是没有对参数$\mathbf{w}$进行任何假设的，也就是说其可以符合任何分布。这个很不贝叶斯，如果我们能对参数引入合理的先验假设，那么就能提高其泛化性能[5]。我们不妨假设$\mathbf{w}$符合高斯分布，其均值为0，方差为一个对角矩阵（既是假设每个参数之间独立，其中$\alpha$控制了每个参数的range），数学表达为：</p><script type="math/tex; mode=display">p(\mathbf{w}|\alpha) = \mathcal{N}(\mathbf{w}|\mathbf{0},\alpha^{-1}\mathbf{I}) \\= (\frac{\alpha}{2\pi})^{(M+1)/2} \rm{exp}\{-\frac{\alpha}{2}\mathbf{w}^T\mathbf{w}\}\tag{2.1 对参数的先验假设}</script><p>其中$M$为多项式次数。如同$\alpha$这样的，控制着整个模型的超空间形状的参数，称之为<strong>超参数(hyperparameters)</strong>。<br>引入了这个先验假设后，我们模型的后验：</p><script type="math/tex; mode=display">p(\mathbf{w}|\mathbf{x},\mathbf{t},\alpha,\beta) \propto p(\mathbf{t}|\mathbf{x},\mathbf{w},\beta)p(\mathbf{w}|\alpha)\tag{2.2}</script><p>我们现在可以在给定了训练集${\mathbf{x},\mathbf{t}}$的情况下，通过找到一个最可能的$\mathbf{w}$来估计出$\mathbf{w}$。换句话说，我们可以最大化这个后验概率，这个技术称之为<strong>最大后验概率法(MAximum Posterior,MAP)</strong>。取(2.2)的负对数，我们有:</p><script type="math/tex; mode=display">\ln{p(\mathbf{w}|\mathbf{x},\mathbf{t},\alpha,\beta)} \propto\ln{p(\mathbf{t}|\mathbf{x},\mathbf{w},\beta)}+\ln{p(\mathbf{w}|\alpha)}\tag{2.3}</script><p>结合(1.6)和(2.1)，舍弃掉和$\mathbf{w}$无关的项之后，我们有：</p><script type="math/tex; mode=display">\frac{\beta}{2}\sum_{n=1}^N \{y(x_n,\mathbf{w})-t_n\}^2+\frac{\alpha}{2}\mathbf{w}^T\mathbf{w} \\\Rightarrow \frac{1}{2}\sum_{n=1}^N \{y(x_n,\mathbf{w})-t_n\}^2+\frac{\alpha}{\beta}\mathbf{w}^T\mathbf{w}</script><p>令$\gamma=\dfrac{\alpha}{\beta}$，于是我们就有了在正则项中最常见到的L2正则项$\dfrac{\gamma}{2}\mathbf{w}^T\mathbf{w}$了。于是我们得到结论：<br>$\nabla$<strong>在贝叶斯理论中，L2正则项是在参数$\mathbf{w}$符合0均值高斯分布的情况下推导出来的，其系数$\gamma$决定了正则的程度。</strong>$\nabla$</p><hr><h1 id="最终一步，贝叶斯曲线拟合"><a href="#最终一步，贝叶斯曲线拟合" class="headerlink" title="最终一步，贝叶斯曲线拟合"></a>最终一步，贝叶斯曲线拟合</h1><p>在上一步中，虽然我们根据最大后验法估计出了$\mathbf{w}$，但是对于曲线拟合来说，这并不是我们的最终目标，我们的最终目标是估计出目标值$\hat{\mathbf{t}}$出来。在完全的贝叶斯处理过程中，我们的估计出来的$\mathbf{w}$是一个分布，为了得到预测值$\hat{\mathbf{t}}$，我们要用概率的加法和乘法法则，对所有可能的$\mathbf{w}$进行积分，得到目标值。这个操作将在贝叶斯理论中一直沿用。<br>具体到我们的曲线拟合的例子，当我们给定了训练集${\mathbf{x},\mathbf{t}}$的时候，当输入一个新的输入$x$的时候，我们期望得到其预测值$t$。也就是说我们需要得出$p(t|x,\mathbf{x},\mathbf{t})$，由概率的基本和积定理有：</p><script type="math/tex; mode=display">p(t|x,\mathbf{x},\mathbf{t}) = \int p(t|x,\mathbf{w})p(\mathbf{w}|\mathbf{x},\mathbf{t}) \rm{d} \mathbf{w}\tag{3.1}</script><p>因为采用了共轭先验[6]假设，因此我们的后验概率同样是一个高斯分布。也即是：</p><script type="math/tex; mode=display">p(t|x,\mathbf{x},\mathbf{t}) = \mathcal{N}(t|m(x),s^2(x))\tag{3.2}</script><p>这个时候，均值和方差可以给定为[1] page 31（暂时并不知道怎么算出来的）</p><script type="math/tex; mode=display">m(x) = \beta \phi(x)^T \mathbf{S} \sum_{n=1}^N \phi(x_n) t_n\tag{3.3}</script><script type="math/tex; mode=display">s^2(x) = \beta^{-1}+\phi(x)^T\mathbf{S}\phi(x)\tag{3.4}</script><script type="math/tex; mode=display">\mathbf{S}^{-1} = \alpha\mathbf{I}+\beta \sum_{n=1}^N \phi(x_n)\phi(x)^T\tag{3.5}</script><p>其中的$\phi(x)=x^i,i=0,\cdots,M$。<br>可以观察到，这个均值$m(x)$是取决于$x$的，在式子(3.4)中的第一项，代表了因为目标的噪声所带来的不确定性。而第二项，表示了因为$\mathbf{w}$的不确定所带来的不确定性，这个正是贝叶斯处理所带来的结果。下图的绿线表示了生成样本的基线，蓝色样本表示基线上添加高斯噪声的结果，红线是预测的均值，红区域是正负1个标准差的区域。<br><img src="/imgs/bayesian/curve.png" alt="curve"></p><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] Bishop C M. Pattern recognition and machine learning (information science and statistics) springer-verlag new york[J]. Inc. Secaucus, NJ, USA, 2006.<br>[2] <a href="https://blog.csdn.net/loseinvain/article/details/80499147">《概率学派和贝叶斯学派的区别》</a><br>[3] <a href="https://blog.csdn.net/loseinvain/article/details/78245665">《 &lt;机器学习系列&gt; 线性回归模型》</a><br>[4] <a href="https://blog.csdn.net/LoseInVain/article/details/78243051">《随机梯度下降法，批量梯度下降法和小批量梯度下降法以及代码实现》</a><br>[5] <a href="https://blog.csdn.net/LoseInVain/article/details/78108990">《机器学习模型的容量，过拟合与欠拟合》</a><br>[6] <a href="https://blog.csdn.net/baimafujinji/article/details/51374202">《先验概率、后验概率以及共轭先验》</a></p><blockquote id="fn_1"><sup>1</sup>. A curve obtained by fitting polynomials to each ordinate of an ordered sequence of points. 指的是用多项式函数$f(\textbf{X}; \theta)=\sum_{i=0}^N \theta_i x_i^{i}, \textbf{X} \in \mathbb{R}^N$。其中如果指数全部变为1而不是$i$，则退化为线性回归。<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt; 

&lt;p&gt;&lt;strong&gt;在以前文章中，我们讨论过&lt;a href=&quot;https://blog.csdn.net/loseinvain/article/details/80499147&quot;&gt;《概率学派和贝叶斯学派的区别》
      
    
    </summary>
    
      <category term="Bayesian Theory" scheme="https://blog.csdn.net/LoseInVain/categories/Bayesian-Theory/"/>
    
    
      <category term="贝叶斯理论" scheme="https://blog.csdn.net/LoseInVain/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/"/>
    
      <category term="统计学习方法" scheme="https://blog.csdn.net/LoseInVain/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
      <category term="概率论" scheme="https://blog.csdn.net/LoseInVain/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"/>
    
      <category term="贝叶斯曲线拟合" scheme="https://blog.csdn.net/LoseInVain/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%9B%B2%E7%BA%BF%E6%8B%9F%E5%90%88/"/>
    
      <category term="正则" scheme="https://blog.csdn.net/LoseInVain/tags/%E6%AD%A3%E5%88%99/"/>
    
  </entry>
  
  <entry>
    <title>用pytorch踩过的坑</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/22/pytorch/pytorch_debug/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/22/pytorch/pytorch_debug/</id>
    <published>2018-10-21T23:47:21.410Z</published>
    <updated>2018-10-21T23:49:12.645Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font> </p><h1 id="pytorch的交叉熵"><a href="#pytorch的交叉熵" class="headerlink" title="pytorch的交叉熵"></a>pytorch的交叉熵</h1><p>pytorch的交叉熵<code>nn.CrossEntropyLoss</code>在训练阶段，里面是内置了<code>softmax</code>操作的，因此只需要喂入原始的数据结果即可，不需要在之前再添加<code>softmax</code>层。这个和tensorflow的<code>tf.softmax_cross_entropy_with_logits</code>如出一辙.[1][2]</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1]. <a href="https://discuss.pytorch.org/t/why-does-crossentropyloss-include-the-softmax-function/4420" target="_blank" rel="noopener">Why does CrossEntropyLoss include the softmax function?</a><br>[2]. <a href="https://discuss.pytorch.org/t/do-i-need-to-use-softmax-before-nn-crossentropyloss/16739/2" target="_blank" rel="noopener">Do I need to use softmax before nn.CrossEntropyLoss()?</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt; &lt;/p&gt;
&lt;h1 id=&quot;pytorch的交叉熵&quot;&gt;&lt;a href=&quot;#pytorch的交叉熵&quot; class=&quot;headerlink&quot; title=&quot;pytorch的交叉熵&quot;&gt;&lt;/a&gt;pytorch的交叉熵&lt;/
      
    
    </summary>
    
      <category term="Pytorch Basic API" scheme="https://blog.csdn.net/LoseInVain/categories/Pytorch-Basic-API/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Deep-Learning/"/>
    
      <category term="Pytorch" scheme="https://blog.csdn.net/LoseInVain/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>《贝叶斯之旅》第二讲，分类问题的两大过程，推理和决策</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/21/bayesian/cls_stage/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/21/bayesian/cls_stage/</id>
    <published>2018-10-21T15:53:57.665Z</published>
    <updated>2018-10-21T15:58:17.388Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br><strong>前面[1]我们介绍了贝叶斯决策的一些知识，介绍了基于最小化分类错误率和最小化分类损失的两种决策准则，接下来，我们简单讨论下分类问题中的二个步骤，推理和决策。</strong></p><p><strong>如有谬误，请联系指正。转载请注明出处。</strong></p><p><em>联系方式：</em><br><strong>e-mail</strong>: <code>FesianXu@163.com</code><br><strong>QQ</strong>: <code>973926198</code><br><strong>github</strong>: <code>https://github.com/FesianXu</code></p><hr><h1 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h1><p>我们在之前的文章中已经介绍过分类问题了，简单的说就是给定一个样本$\bf{x} \in \mathbb{R}^n$，将其划分到有限的标签集$\bf{Y} \in {0,1,\cdots,m}$中。通常来说，我们可以将整个分类问题划分为两个独立的过程，分别是<strong>推理（inference）</strong>和<strong>决策(decision)</strong>阶段。在推理阶段，我们通过已有的训练集，学习到后验概率$p(\mathcal{C}_k|\bf{x})$，或者也可以通过学习联合概率分布$p(\mathcal{C}_k, \bf{x})$，然后也可以得到后验概率。而接下来，在决策阶段，就根据这个后验概率，对样本的类别进行判断决策。这个决策过程可以参考文章[1]的讨论。</p><p><strong>注意到，很多时候，这两个过程可以合在一起，将问题简化为成：学习一个映射$f(\bf{x}) \in \mathbb{R}^m, \bf{x} \in \mathbb{R}^n$，直接将样本映射到类别标签。</strong>这个过程中，将不会涉及到任何的后验概率等，而是直接得出预测结果，这个函数因此称之为<strong>判别函数(Discriminant function)</strong>。[2] page 43</p><p>事实上，这些讨论过的方法都可以用来解决分类问题，并且在实际应用中都有所应用，我们按照复杂程度进行降序排列之后，有：</p><ol><li><p>通过解决推理问题之后，我们可以给每一个类别估计出类条件概率$p(\mathbf{x}|\mathcal{C}_k)$，同时，先验概率$p(\mathcal{C}_k)$也很容易可以估计出来，然后通过贝叶斯公式我们可以得到后验概率：</p><script type="math/tex; mode=display">p(\mathcal{C}_k | \mathbf{x}) = \frac{p(\mathbf{x}|\mathcal{C}_k)p(\mathcal{C}_k)}{p(\mathbf{x})}\tag{1.1}</script><p>我们有:</p><script type="math/tex; mode=display">p(\mathbf{x}) = \sum_{k} p(\mathbf{x}|\mathcal{C}_k)p(\mathcal{C}_k)\tag{1.2 对输入分布进行建模}</script><p>等价地，我们可以对联合概率密度$p(\mathbf{x},\mathcal{C}_k)$进行建模，然后进行标准化后得到后验概率。像这种显式地或者隐式地对输入和输出进行概率分布建模的模型，称之为<strong>生成模型(generative models)</strong>，因为从这个联合分布中进行采样可以生成输入空间中的一些<strong>虚假生成数据(synthetic data)</strong>。</p></li><li><p>通过解决推理问题后，得到后验概率$p(\mathcal{C}_k|\mathbf{x})$，然后通过决策论进行类别判断。这种模型称之为<strong>判别模型(Discriminative model)</strong>。</p></li><li>寻找一个函数$f(\mathbf{x})$，称之为判别函数，直接将输入的$\mathbf{x}$映射到一个类别标签上，比如SVM分类器等。在这个情形下，并没有用到任何概率，也就是说我们对预测的结果其实是没有办法判断可靠程度的。</li></ol><p>我们接下来分别讨论下这三种方法的优劣点。</p><hr><h1 id="孰优孰劣，判别模型和生成模型"><a href="#孰优孰劣，判别模型和生成模型" class="headerlink" title="孰优孰劣，判别模型和生成模型"></a>孰优孰劣，判别模型和生成模型</h1><h2 id="生成模型"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型</h2><p>生成模型是对于数据量需求最高的，同时运算量也是最大的，因为其需要训练出包含$\mathbf{x}$和$\mathcal{C}_k$的联合分布，如果数据量不够，将会导致严重的过拟合现象[3]。对于很多应用下来说，$\mathbf{x}$是一个维度很高的特征向量，因此为了使得类条件概率得到一个较为合理的精度，就需要很多的数据量进行计算。但是，生成模型也有一些很好的性质，比如说可以从中进行采样生成出一些假数据，这个应用目前在很多image inpainting[4]，style transfer[5]任务中经常用到。而且，因为通过联合概率分布可以通过式子(1.2)计算出边缘概率分布$p(\mathbf{x})$。这个输入空间的边缘概率分布很有用，因为其可以判断输入的新数据是否是一个所谓的<strong>离群点(outlier)</strong>，离群点如下图所示。这个就是所谓的<strong>离群点检测(outlier detection)</strong>或者称之为<strong>异常检测(novelty detection)</strong>，这个在网络欺诈预测，银行欺诈预测，电子垃圾邮件检测中很有用。</p><p><img src="/imgs/bayesian/outlier.jpg" alt="outlier"></p><h2 id="判别模型"><a href="#判别模型" class="headerlink" title="判别模型"></a>判别模型</h2><p>在分类任务中，很多时候你只是做个分类而已，并不用进行离群点检测，也不需要生成虚假样本.这个时候，如果还用生成模型去进行后验概率的估计，就浪费了很多资源。我们观察下图，我们可以发现，类条件概率其实和后验概率并没有必然的影响。这个时候，你就需要采用判别模型。<br><img src="/imgs/bayesian/posterior_class.png" alt="posterior_class"><br>不仅如此，采用了判别模型还有一个好处就是，可以利用所谓的<strong>拒绝域(reject option)</strong>把一些过于边缘的判断拒绝掉。比如我们仅有10%的把握判断某人为癌症患者，那么我们就情愿不做这个判断，交给更为权威的人或者系统进行下一步的处理。如下图所示，绿色的水平线表示拒绝水平，只有后验概率高于这个水平线，才能认为是可靠的判断。我们将会看到，在基于判别函数的情况下，因为并没有概率的存在，因此并不能进行这种操作。</p><p><img src="/imgs/bayesian/reject.png" alt="reject"></p><h2 id="判别函数方法"><a href="#判别函数方法" class="headerlink" title="判别函数方法"></a>判别函数方法</h2><p>有比以上俩种方法更为简单，计算量更少的方法，那就是判别函数法。在这个情况下，因为是直接用训练数据拟合一个函数$f(\mathbf{x})$对样本进行分类，因此无法得到后验概率$p(\mathcal{C}_k|\mathbf{x})$。在这个方法中，只能最小化分类错误率，而没法给不同类型的分类错误进行区别[1]，采用最小化分类风险，这是个遗憾的地方。</p><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] <a href="https://blog.csdn.net/LoseInVain/article/details/82780472">《贝叶斯之旅||第一讲，贝叶斯决策》</a></p><p>[2] Bishop C M. Pattern recognition and machine learning (information science and statistics) springer-verlag new york[J]. Inc. Secaucus, NJ, USA, 2006.</p><p>[3] <a href="https://blog.csdn.net/LoseInVain/article/details/78108990">《机器学习模型的容量，过拟合与欠拟合》</a></p><p>[4] <a href="https://blog.csdn.net/gavinmiaoc/article/details/80802967">《基于深度学习的Image Inpainting (图像修复)论文推荐(持续更新)》</a></p><p>[5] <a href="https://www.jianshu.com/p/b1189448eb2e" target="_blank" rel="noopener">《Image Style Transfer》</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;strong&gt;前面[1]我们介绍了贝叶斯决策的一些知识，介绍了基于最小化分类错误率和最小化分类损失的两种决策准则，接下来，我们简单讨论下分类问题中的二个步骤，推理和决策。&lt;/strong&gt;&lt;/p&gt;
&lt;p
      
    
    </summary>
    
      <category term="Bayesian Theory" scheme="https://blog.csdn.net/LoseInVain/categories/Bayesian-Theory/"/>
    
    
      <category term="贝叶斯理论" scheme="https://blog.csdn.net/LoseInVain/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/"/>
    
      <category term="统计学习方法" scheme="https://blog.csdn.net/LoseInVain/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
      <category term="概率论" scheme="https://blog.csdn.net/LoseInVain/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>《贝叶斯之旅》第一讲，贝叶斯决策</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/21/bayesian/bayesian_decision/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/21/bayesian/bayesian_decision/</id>
    <published>2018-10-21T15:40:47.917Z</published>
    <updated>2018-10-21T15:52:41.246Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br><strong>在机器学习中，有两大门派，分别是频率学派和贝叶斯学派，在现在深度学习大行其道的时代下，数据量空前庞大，频率学派占据了比较大的优势，而贝叶斯学派似乎有点没落，然而，贝叶斯理论在机器学习中是有着很重要的地位的，它从理论上揭示了模型为什么可以工作，为什么会fail，在数据量必须小的一些任务中，通常也可以表现得比频率学派的好，让我们开始我们的贝叶斯之旅吧。这一讲，主要阐述的是在贝叶斯的观点中，我们如何根据现有的数据和假设，对未知的样本进行分类决策。</strong></p><p><strong>如有谬误，请联系指正。转载请注明出处。</strong></p><p><em>联系方式：</em><br><strong>e-mail</strong>: <code>FesianXu@163.com</code><br><strong>QQ</strong>: <code>973926198</code><br><strong>github</strong>: <code>https://github.com/FesianXu</code></p><hr><h1 id="为什么要贝叶斯"><a href="#为什么要贝叶斯" class="headerlink" title="为什么要贝叶斯"></a>为什么要贝叶斯</h1><p>我们在以前的文章<a href="https://blog.csdn.net/LoseInVain/article/details/80499147">《概率派和贝叶斯派的区别》</a>中，曾经讨论过频率学派和贝叶斯学派看待未知模型参数的一些观点，我们这里简单描述下就是：</p><blockquote><p>频率学派相信我们的模型参数尽管未知，但是其是有一个真实的值$\theta$的，只要我们的样本足够多，我们就可以准确无偏地估计出这个真实的值出来；而贝叶斯学派相信我们的模型的未知参数是一个随机变量，而不是一个简简单单的值，因此是符合一个分布的。也就是说，基于我们现有的样本数据，我们对模型中的未知参数的估计都是估计出这些未知参数先验分布的一些参数而已，比如高斯分布的均值和协方差矩阵等等，在贝叶斯学派眼中，模型的参数本身就不是确定的，因此只能用随机变量表达。</p></blockquote><p>我们从以上的区别中可以看出，在贝叶斯模型中，因为每个参数都是一个随机变量，也即是符合某个分布的，如果我们对数据的来源有一定的自信（比如我们的数据是关于电子科技大学的男女比例，我们就会知道这个比例将会大到爆炸，这个我们是很有自信的，因此可以作为先验概率引入的。），那么你将可以通过假设参数分布的形式，引入你对数据的<strong>先验知识</strong>（prior knowledge），我们称之为对参数的先验假设，表示为$p(\theta)$。我们以后将会发现，如果这个先验知识<strong>足够合理</strong>，将会使得模型即使是在小规模的数据上训练，都可以获得较为理想的效果，这点是频率学派模型较难做到的。</p><p>总结来说，也就是<strong>贝叶斯模型在小数据集上具有更好的泛化性能</strong>，至于什么叫泛化性能，参考以前文章<a href="https://blog.csdn.net/LoseInVain/article/details/78746520">《经验误差，泛化误差》</a>。</p><hr><h1 id="利用贝叶斯理论进行分类"><a href="#利用贝叶斯理论进行分类" class="headerlink" title="利用贝叶斯理论进行分类"></a>利用贝叶斯理论进行分类</h1><p>在进行进一步讨论之前，我们对我们接下来需要用的的符号进行统一的规定表示和解释：</p><ol><li><strong>样本(sample)</strong>，$\mathbf{x} \in \mathbb{R}^n$，其中的$n$称之为样本的<strong>维度(dimension)</strong>。</li><li><strong>状态(state)</strong>，第一类：$\omega = \omega_1$;第二类：$\omega = \omega_2$，在其他文献中，这个通常也称之为<strong>类别(class)</strong>，指的是某个样本配对的类别属性。</li><li><strong>先验概率(prior)</strong>，$p(\omega_1)$，$p(\omega_2)$，指的是对某些类别的预先知道的知识，比如在预测某个病人是否是癌症病人的例子，在没有得到任何关于这个病人的信息之前，因为我们知道得癌症是一个较为低概率的事件，因此其先验概率$p(\omega=癌症)$是一个很小的值。先验概率表现了我们对于某个知识的“信仰”。</li><li><strong>样本分布密度(sample distribution density)</strong>，$p(\mathbf{x})$。</li><li><strong>类条件概率密度(class-conditional probablity density)</strong>，$p(\mathbf{x}|\omega_1)$,$p(\mathbf{x}|\omega_2)$，这个概率也经常被称之为<strong>似然概率(likelihood probablity)</strong>。</li></ol><p>以上的术语将会在以后的文章中经常见到，我们届时再做更加深入的讨论。</p><hr><p>让我们考虑一个情景：</p><blockquote><p>给你$n$个样本作为已知的训练集，$\mathbf{X}={\mathbf{x}_1,\mathbf{x}_2,\cdots,\mathbf{x}_n}$，其对应的标签为，$\mathbf{Y}={\mathbf{y}_1}$，先给你一个新的样本$\mathbf{x}$，其需要预测其标签。</p></blockquote><p>这个就是基本的分类问题的情景，为了简便，不妨将这里的标签看成是二分类标签$\mathbf{y}_i \in {+1,-1}$。我们可以将这个分类问题等价为求$p(\omega_1|\mathbf{x})$和$p(\omega_2|\mathbf{x})$的概率大小，一般来说，如果$p(\omega_1|\mathbf{x}) &gt; p(\omega_2|\mathbf{x})$，那么就可以将其判断为第一类了对吧！反之亦然。</p><p>因为有概率论中的贝叶斯公式，我们有：</p><script type="math/tex; mode=display">p(\omega_i|\mathbf{x}) = \frac{p(\omega_i,\mathbf{x})}{p(\mathbf{x})}=\frac{p(\omega_i)p(\mathbf{x}|\omega_i)}{\sum_{j=1}^M p(\omega_i)p(\mathbf{x}|\omega_i)}\tag{1.1 贝叶斯公式}</script><p>因为$p(\mathbf{x})$在$p(\omega_1|\mathbf{x})$和$p(\omega_2|\mathbf{x})$都是一样的，因此在分类问题中，一般可以忽略这个项，我们有：</p><script type="math/tex; mode=display">p(\omega_i|\mathbf{x}) \propto p(\omega_i)p(\mathbf{x}|\omega_i)\tag{1.2 贝叶斯公式常用形式}</script><p>其中，$p(\omega_i)$称之为<strong>先验概率</strong>；$p(\mathbf{x}|\omega_i)$称之为<strong>似然概率</strong>，或者称之为<strong>类条件概率</strong>；$p(\omega_i|\mathbf{x})$称之为<strong>后验概率(posterior)</strong>。其中，因为我们已经有了先前样本$\mathbf{X}$以及其对应的标签$\mathbf{Y}$，因此可以估计出先验概率和似然概率出来（一般情况下，需要对似然概率进行建模，我们后续再讨论）。</p><p>$\nabla$<strong>总而言之，我们通过人工的先验概率，和从已有数据中学习到的似然概率中，可以得到后验概率，而后验概率为我们的分类提供了很重要的依据。</strong>$\nabla$</p><hr><h1 id="决策论，如何做出一个合理的选择"><a href="#决策论，如何做出一个合理的选择" class="headerlink" title="决策论，如何做出一个合理的选择"></a>决策论，如何做出一个合理的选择</h1><p>机器学习整个过程可以分为两个阶段，一是<strong>推理(inference)</strong>阶段，二是<strong>决策(decision)</strong>阶段。推理阶段主要是从训练样本集中估计出$p(\mathbf{x}, \mathbf{t})$分布，决策阶段是根据这个联合概率分布，如何作出一个合理的决策，对样本进行分类。</p><p><strong>决策论(Decision Theory)</strong>[1]指导我们如何根据在推理阶段得出的$p(\mathbf{x}, \mathbf{t})$分布进行合理的分类。一般来说，决策策略可分为<strong>最小错误分类率</strong>策略和<strong>最小期望损失</strong>策略，我们分别介绍下。</p><h2 id="最小错误分类率"><a href="#最小错误分类率" class="headerlink" title="最小错误分类率"></a>最小错误分类率</h2><p><strong>最小分类错误率(minimizing the misclassification rate)</strong>策略的主要目的就是让分类错误率最小化，这个在大多数情况下是适用的。我们先对分类错误率这个概念进行定义，显然，考虑二分类情况，将类别1的物体分类到了2或者相反就是误分类了，用数学表达式表达就是：</p><script type="math/tex; mode=display">p(\rm{mistake}) = p(\mathbf{x} \in \mathcal{R}_1,\mathcal{C}_2)+ p(\mathbf{x} \in \mathcal{R}_2,\mathcal{C}_1) \\= \int_{\mathcal{R}_1} p(\mathbf{x},\mathcal{C}_2) \rm{d}\mathbf{x}+\int_{\mathcal{R}_2} p(\mathbf{x},\mathcal{C}_1) \rm{d}\mathbf{x}</script><p>其中的$\mathcal{R}_k$称之为<strong>决策区域(decision regions)</strong>，如果输入向量在决策区域$k$下，那么该输入向量的所有样本都是被预测为了$k$类。$p(\mathbf{x} \in \mathcal{R}_i, \mathcal{C}_j)$表示将属于类别$j$的样本分类为了类别$i$。对于一个新样本$\mathbf{x}$，为了最小化$p(\rm{mistake})$，我们应该将其类别分到式子(2.1)中的被积函数中较小的一个，因为这样，较大的一项就会因为决策区域不适合而变为0了，因此只会剩下一项较小的。换句话说，就是如果$p(\mathbf{x},\mathcal{C}_1) &gt; p(\mathbf{x},\mathcal{C}_2)$，那么就将其预测为$\mathcal{C}_1$。</p><hr><p>我们这里引用[1] <em>page 40</em> 给出的图示进行理解，如下图所示，其中$\hat{x}$表示决策边界，大于$\hat{x}$将会被预测为第二类，小于则会被预测为第一类，于是，我们的决策错误率就是红色区域，绿色区域和蓝色区域的面积了。我们可以清楚的发现，不管$\hat{x}$怎么移动，绿色和蓝色区域的和是一个常数，只有红色区域会在变化，因此直观上看，只有当$\hat{x} = x_0$的时候，也就是$p(x,\mathcal{C_1})=p(x,\mathcal{C_2})$的时候，才会有最小分类错误率。我们有：</p><script type="math/tex; mode=display">p(x,\mathcal{C_1})=p(x,\mathcal{C_2}) \\\Rightarrow p(\mathcal{C}_1|x)p(x) = p(\mathcal{C}_2|x)p(x) \\\Rightarrow p(\mathcal{C_1|x}) = p(\mathcal{C_2|x})\tag{2.2 最优决策}</script><p>也就是说，当$p(\mathcal{C_1|x}) &gt; p(\mathcal{C_2|x})$时，选择$\mathcal{C}_1$作为理论分类错误率最小的选择。我们可以发现，选择具有最大后验概率的类别作为预测结果能够达到最小分类错误率的效果，这个原则我们称之为<strong>最大后验概率原则</strong>，同时，我们留意，在参数估计中也有一个称之为<strong>最大后验概率估计(maximize a posterior probablity, MAP)</strong>的原则，请不要混淆。<br><img src="/imgs/bayesian/map.png" alt="map"></p><hr><p>当类别多于2类时，比如有$K$类时，计算正确率将会更加方便，我们有：</p><script type="math/tex; mode=display">p(\rm{correct}) = \sum_{k=1}^K p(\mathbf{x} \in \mathcal{R}_k, \mathcal{C}_k) \\= \sum_{k=1}^K \int_{\mathcal{R}_k} p(\mathbf{x},\mathcal{C}_k) \rm{d} \mathbf{x} \tag{2.3 多类分类的正确率}</script><p>同理的，同样是选择具有最大后验概率的类别作为预测结果，能够达到最小分类错误率。</p><p><strong>注意到，这个原则有一些等价的表达形式，我们将会在这个系列的附录中进行补充。</strong></p><hr><h2 id="最小期望损失"><a href="#最小期望损失" class="headerlink" title="最小期望损失"></a>最小期望损失</h2><p>按道理来说，最小分类错误已经可以在绝大多数任务中使用了，但是有一些任务，比如医生根据CT影像对病人进行癌症的诊断，在这些任务中，<strong>错报</strong>和<strong>漏报</strong>可有着不同的后果。如果只是<strong>错报</strong>，将没有疾病的人诊断为病人，顶多再去进行一次体检排查，但是如果将有癌症的患者漏报成没有疾病的人，那么就可能错失了最佳的治疗时机，因此这种情况下，这两种错误方式可有着不同的<strong>代价</strong>。</p><p>为了对这个代价进行数学描述，我们引入了一个<strong>损失矩阵(loss matrix)</strong>用来描述不同错误分类带来的不同代价：</p><div class="table-container"><table><thead><tr><th></th><th>cancer</th><th>normal</th></tr></thead><tbody><tr><td>cancer</td><td>0</td><td>1000</td></tr><tr><td>normal</td><td>1</td><td>0</td></tr></tbody></table></div><p>这个矩阵很好的描述了我们刚才的需求，让我们用$L$表示，其中$L_{i,j}$表示其第$i$行,$j$列的元素。与最小化分类错误率不同的，我们定义一个代价函数：</p><script type="math/tex; mode=display">\mathbb{E}[L] = \sum_{k} \sum_{j} \int_{\mathcal{R}_j} L_{k,j}p(\mathbf{x}, \mathcal{C}_k) \rm{d} \mathbf{x}\tag{3.1 代价函数}</script><p>我们的目标是最小化(3.1)。<br>当然，如果你需要对一个样本$\mathbf{x}$作出决策，你也许需要将其分解为：</p><script type="math/tex; mode=display">R(\alpha_k|\mathbf{x}) = \sum_j  L_{k,j}p(\mathcal{C}_k|\mathbf{x})\tag{3.2 分类风险}</script><p>这里的$R(\cdot)$表示Risk，表示分类为$k$类的风险，当然是越小越好。</p><p>因此总结来说，最小化风险的计算步骤为：</p><ol><li><strong>计算后验概率</strong>： <script type="math/tex; mode=display">p(\mathcal{C}_k|x) = \frac{p(x|\mathcal{C}_k) p(\mathcal{C}_k)}{\sum_{i=1}^c p(x|\mathcal{C}_i)p(\mathcal{C}_i)} \\k = 1,2,\cdots,c</script></li><li><strong>计算风险</strong>：<script type="math/tex; mode=display">R(\mathcal{R}_k|\mathbf{x}) = \sum_j  L_{k,j}p(\mathcal{C}_k|\mathbf{x})</script></li><li><strong>决策</strong>：<script type="math/tex; mode=display">\alpha = \arg \min _{i = 1, \cdots, c} R(\alpha_i | x)</script></li></ol><p><strong>显然，当损失矩阵是一个单位矩阵的时候，最小分类错误率和最小分类风险等价。</strong></p><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] Bishop C M. Pattern recognition and machine learning (information science and statistics) springer-verlag new york[J]. Inc. Secaucus, NJ, USA, 2006.<br>[2] 张学工. 模式识别[J]. 2010.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;strong&gt;在机器学习中，有两大门派，分别是频率学派和贝叶斯学派，在现在深度学习大行其道的时代下，数据量空前庞大，频率学派占据了比较大的优势，而贝叶斯学派似乎有点没落，然而，贝叶斯理论在机器学习中是有
      
    
    </summary>
    
      <category term="Bayesian Theory" scheme="https://blog.csdn.net/LoseInVain/categories/Bayesian-Theory/"/>
    
    
      <category term="贝叶斯理论" scheme="https://blog.csdn.net/LoseInVain/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/"/>
    
      <category term="统计学习方法" scheme="https://blog.csdn.net/LoseInVain/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
      <category term="概率论" scheme="https://blog.csdn.net/LoseInVain/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow高阶函数之 tf.foldl()和tf.foldr()</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/21/tensorflow/tf.foldr()/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/21/tensorflow/tf.foldr()/</id>
    <published>2018-10-21T13:24:54.518Z</published>
    <updated>2018-10-21T13:25:35.316Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br>在TensorFlow中有着若干高阶函数，如之前已经介绍过了的<code>tf.map_fn()</code>，见博文<a href="https://blog.csdn.net/LoseInVain/article/details/78815130">TensorFlow中的高阶函数：tf.map_fn()</a>，此外，还有几个常用的高阶函数，分别是<code>tf.foldl()</code>，<code>tf.foldr()</code>，我们简要介绍下。</p><hr><p><code>tf.foldl()</code>类似于python中的<code>reduce()</code>函数，假设<code>elems</code>是一个大于等于一阶的张量或者列表，形状如<code>[n,...]</code>，那么该函数将会重复地调用<code>fn</code>与这个列表上，从左到右进行处理，这里讲得不清楚，我们看看官方的API手册和一些例子理解一下，地址：<a href="https://www.tensorflow.org/api_docs/python/tf/foldl" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/foldl</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.foldl(</span><br><span class="line">    fn,</span><br><span class="line">    elems,</span><br><span class="line">    initializer=<span class="keyword">None</span>,</span><br><span class="line">    parallel_iterations=<span class="number">10</span>,</span><br><span class="line">    back_prop=<span class="keyword">True</span>,</span><br><span class="line">    swap_memory=<span class="keyword">False</span>,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p>其中<code>fn</code>是一个可调用函数，也可以用lambda表达式；<code>elems</code>是需要处理的列表；<code>initializer</code>是一个可选参数，可以作为<code>fn</code>的初始累加值（accumulated value）；至于<code>parallel_iterations</code>是并行数，其他的函数可以查询官网，就不累述了。<br>最重要的参数无非是<code>fn</code>,<code>elems</code>和<code>initializer</code>，其中<code>fn</code>是一个具有两个输入参数的函数，需要返回一个值作为累计结果，<code>elems</code>是一个列表或者张量，用于被<code>fn</code>累计处理。形象的来说，就是<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.foldl(fn,elems=[x1,x2,x3,x4]) = fn(fn(fn(x1,x2),x3),x4)</span><br></pre></td></tr></table></figure></p><p>如果给定了<code>initializer</code>，那么初始的累计参数（也就是<code>fn</code>的第一个参数）就是他了，如果没有给定，也即是<code>initializer=None</code>那么<code>elems</code>中必须至少有一个值，第一个值将会被作为初始值。例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">elems = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">sum = tf.foldl(<span class="keyword">lambda</span> a, x: a + x, elems)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  print(sess.run(sum))</span><br></pre></td></tr></table></figure></p><p>将会输出21，也即是(((((1+2)+3)+4)+5)+6)，如果给定了一个初始化值，就变为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">elems = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">sum = tf.foldl(<span class="keyword">lambda</span> a, x: a + x, elems,initializer=<span class="number">10</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  print(sess.run(sum))</span><br></pre></td></tr></table></figure></p><p>输出变为31。此处的累加是最简单的应用，还可以有更多复杂的应用，就看应用场景了。至于<code>tf.foldr()</code>和这个函数是基本上一样的，无非就是从右边开始计算到左边而已。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;在TensorFlow中有着若干高阶函数，如之前已经介绍过了的&lt;code&gt;tf.map_fn()&lt;/code&gt;，见博文&lt;a href=&quot;https://blog.csdn.net/LoseInVain/a
      
    
    </summary>
    
      <category term="TensorFlow Basic API" scheme="https://blog.csdn.net/LoseInVain/categories/TensorFlow-Basic-API/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="https://blog.csdn.net/LoseInVain/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>tf.group()用于组合多个操作</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/21/tensorflow/tf_group/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/21/tensorflow/tf_group/</id>
    <published>2018-10-21T13:23:56.724Z</published>
    <updated>2018-10-21T13:24:25.326Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br><code>tf.group()</code>用于创造一个操作，可以将传入参数的所有操作进行分组。<a href="https://www.tensorflow.org/api_docs/python/tf/group" target="_blank" rel="noopener">API手册</a>如:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.group(</span><br><span class="line">    *inputs,</span><br><span class="line">    **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p><code>ops = tf.group(tensor1, tensor2,...)</code><br>其中<code>*inputs</code>是0个或者多个用于组合tensor，一旦<code>ops</code>完成了，那么传入的<code>tensor1,tensor2,...</code>等等都会完成了，经常用于组合一些训练节点，如在Cycle GAN中的多个训练节点，例子如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">generator_train_op = tf.train.AdamOptimizer(g_loss, ...)</span><br><span class="line">discriminator_train_op = tf.train.AdamOptimizer(d_loss,...)</span><br><span class="line">train_ops = tf.groups(generator_train_op ,discriminator_train_op)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(train_ops) </span><br><span class="line">  <span class="comment"># 一旦运行了train_ops,那么里面的generator_train_op和discriminator_train_op都将被调用</span></span><br></pre></td></tr></table></figure></p><p><strong>注意的是，tf.group()返回的是个操作，而不是值，如果你想下面一样用，返回的将不是值</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = tf.Variable([<span class="number">5</span>])</span><br><span class="line">b = tf.Variable([<span class="number">6</span>])</span><br><span class="line">c = a+b</span><br><span class="line">d = a*b</span><br><span class="line">e = a/b</span><br><span class="line">ops = tf.group(c,d,e)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    ee = sess.run(ops)</span><br></pre></td></tr></table></figure></p><p>返回的将不是c,d,e的运算结果，而是一个<code>None</code>，就是因为这个是一个操作，而不是一个张量。如果需要返回结果，请参考<a href="https://www.tensorflow.org/api_docs/python/tf/tuple" target="_blank" rel="noopener"><code>tf.tuple()</code></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;code&gt;tf.group()&lt;/code&gt;用于创造一个操作，可以将传入参数的所有操作进行分组。&lt;a href=&quot;https://www.tensorflow.org/api_docs/python/t
      
    
    </summary>
    
      <category term="TensorFlow Basic API" scheme="https://blog.csdn.net/LoseInVain/categories/TensorFlow-Basic-API/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="https://blog.csdn.net/LoseInVain/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>tf.tuple()用于组合多个张量输入</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/21/tensorflow/tf_tuple/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/21/tensorflow/tf_tuple/</id>
    <published>2018-10-21T13:22:49.287Z</published>
    <updated>2018-10-21T13:23:39.206Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br><code>tf.tuple()</code>用于组合多个张量输入组成的列表<code>[tensor1,tensor2,...]</code>，然后返回一个计算过后的张量列表<code>[cal_tensor1,cal_tensor2,...]</code>，这点和<code>tf.group()</code>是不同的，<a href="https://www.tensorflow.org/api_docs/python/tf/tuple" target="_blank" rel="noopener">API手册</a>如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.tuple(</span><br><span class="line">    tensors,</span><br><span class="line">    name=<span class="keyword">None</span>,</span><br><span class="line">    control_inputs=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p><code>ops = tf.tuple([tensor1,tensor2,...],control_inputs=c_ops)</code><br>其中<code>tensors</code>是由多个<code>tensor</code>组成的列表，其中的<code>control_inputs</code>是添加额外的控制输入，添加的输入<code>c_ops</code>必须在整个<code>ops</code>完成之前得到执行，但是<code>c_ops</code>的输出是不会返回的。</p><p>API上描述，这个可以作为提供一种并行处理的机制，所有的输入的tensor可以并行计算，但是所有tensor的计算出来的值将会以<code>tuple</code>的形式返回，并且这个只能在并行计算完成之后得到。(<em>This can be used as a “join” mechanism for parallel computations: all the argument tensors can be computed in parallel, but the values of any tensor returned by tuple are only available after all the parallel computations are done.</em>)</p><p>使用例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a = tf.Variable([<span class="number">5</span>])</span><br><span class="line">b = tf.Variable([<span class="number">6</span>])</span><br><span class="line">c = a+b</span><br><span class="line">d = a*b</span><br><span class="line">e = a/b</span><br><span class="line">ops = tf.tuple([c,d,e])</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    ee = sess.run(ops)</span><br><span class="line">    print(ee)</span><br></pre></td></tr></table></figure></p><p>输出<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[array([<span class="number">11</span>], dtype=int32), array([<span class="number">30</span>], dtype=int32), array([<span class="number">0.83333333</span>])]</span><br></pre></td></tr></table></figure></p><p>可以和<a href="https://blog.csdn.net/LoseInVain/article/details/81703786">tf.group()用于组合多个操作</a>的例子进行对比。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;code&gt;tf.tuple()&lt;/code&gt;用于组合多个张量输入组成的列表&lt;code&gt;[tensor1,tensor2,...]&lt;/code&gt;，然后返回一个计算过后的张量列表&lt;code&gt;[cal_ten
      
    
    </summary>
    
      <category term="TensorFlow Basic API" scheme="https://blog.csdn.net/LoseInVain/categories/TensorFlow-Basic-API/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="https://blog.csdn.net/LoseInVain/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>pytorch中的L2和L1正则化，自定义优化器设置等操作</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/21/pytorch/pytorch_reg/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/21/pytorch/pytorch_reg/</id>
    <published>2018-10-21T13:19:27.311Z</published>
    <updated>2018-10-21T13:20:31.437Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br>在pytorch中进行L2正则化，最直接的方式可以直接用优化器自带的<code>weight_decay</code>选项指定权值衰减率，相当于L2正则化中的$\lambda$，也就是：</p><script type="math/tex; mode=display">\mathcal{L}_{reg} = ||y-\hat{y}||^2+\lambda||W||^2\tag{1}</script><p>中的$\lambda$。但是有一个问题就是，这个指定的权值衰减是会对网络中的所有参数，包括权值$w$和偏置$b$同时进行的，很多时候如果对$b$进行L2正则化将会导致严重的欠拟合<sup><a href="#fn_1" id="reffn_1">1</a></sup>，因此这个时候一般只需要对权值进行正则即可，当然，你可以获取模型中的所有权值，然后按照定义的方法显式地进行处理，得到一个正则损失之后在交给优化器优化，这是一个通用的方法。但是其实还有更为简单的方法，同样在优化器中提供了。</p><hr><p><code>torch.optim</code>中包含了很多现成的优化器，包括SGD，Adadelta，Adam，Adagrad，RMSprop等，使用它很简单，你需要传入一个可迭代的参数列表（里面必须都是Variable类型的）进行优化，然后你可以指定一些优化器的参数，如学习率，动量，权值衰减等。例子如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.SGD(model.parameters(), lr = <span class="number">0.01</span>, momentum=<span class="number">0.9</span>,weight_decay=<span class="number">1e-5</span>)</span><br><span class="line">optimizer = optim.Adam([var1, var2], lr = <span class="number">0.0001</span>)</span><br></pre></td></tr></table></figure></p><p>此外，优化器还支持一种称之为<strong>Per-parameter options</strong>的操作，就是对每一个参数进行特定的指定，以满足更为细致的要求。做法也很简单，与上面不同的，我们传入的待优化变量不是一个<code>Variable</code>而是一个可迭代的字典，字典中必须有<code>params</code>的key，用于指定待优化变量，而其他的key需要匹配优化器本身的参数设置。我们看一下例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">optim.SGD([</span><br><span class="line">                &#123;<span class="string">'params'</span>: model.base.parameters()&#125;,</span><br><span class="line">                &#123;<span class="string">'params'</span>: model.classifier.parameters(), <span class="string">'lr'</span>: <span class="number">1e-3</span>&#125;</span><br><span class="line">            ], lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure></p><p>其中，我们可以看到，传入的list中有两个字典，每一个都是一个独立的参数组，其中每一组中都有一个<code>params</code>key，用于指定需要训练的参数，如<code>model.base.parameters()</code>就是base网络中的所有参数，尔后，也可以在每一组内单独设置学习率，权值衰减等。如果不显式地在组内设定，那么就会继承优化器的全局参数，如<code>lr=1e-2</code>,<code>momentum=0.9</code>等，如果组内指定了，那么全局的将不会覆盖掉组内的参数设置。<br>这样我们就可以灵活的给每一个子网络设定不同的学习率，权值衰减，momentum了，我们也可以给权值设定权值衰减，而不作用与偏置，如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">weight_p, bias_p = [],[]</span><br><span class="line"><span class="keyword">for</span> name, p <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">  <span class="keyword">if</span> <span class="string">'bias'</span> <span class="keyword">in</span> name:</span><br><span class="line">     bias_p += [p]</span><br><span class="line">   <span class="keyword">else</span>:</span><br><span class="line">     weight_p += [p]</span><br><span class="line"><span class="comment"># 这里的model中每个参数的名字都是系统自动命名的，只要是权值都是带有weight，偏置都带有bias，</span></span><br><span class="line"><span class="comment"># 因此可以通过名字判断属性，这个和tensorflow不同，tensorflow是可以用户自己定义名字的，当然也会系统自己定义。</span></span><br><span class="line">optim.SGC([</span><br><span class="line">          &#123;<span class="string">'params'</span>: weight_p, <span class="string">'weight_decay'</span>:<span class="number">1e-5</span>&#125;,</span><br><span class="line">          &#123;<span class="string">'params'</span>: bias_p, <span class="string">'weight_decay'</span>:<span class="number">0</span>&#125;</span><br><span class="line">          ], lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1]. <a href="https://pytorch.org/docs/stable/optim.html" target="_blank" rel="noopener">PyTorch Documentation -&gt; torch.optim</a></p><blockquote id="fn_1"><sup>1</sup>. Goodfellow I, Bengio Y, Courville A, et al. Deep learning[M]. Cambridge: MIT press, 2016.<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;在pytorch中进行L2正则化，最直接的方式可以直接用优化器自带的&lt;code&gt;weight_decay&lt;/code&gt;选项指定权值衰减率，相当于L2正则化中的$\lambda$，也就是：&lt;/p&gt;
&lt;scr
      
    
    </summary>
    
      <category term="Pytorch Basic API" scheme="https://blog.csdn.net/LoseInVain/categories/Pytorch-Basic-API/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Deep-Learning/"/>
    
      <category term="Pytorch" scheme="https://blog.csdn.net/LoseInVain/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>在TensorFlow中自定义梯度的两种方法</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/21/tensorflow/tf_gradient_define/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/21/tensorflow/tf_gradient_define/</id>
    <published>2018-10-21T12:53:51.927Z</published>
    <updated>2018-10-21T12:58:21.704Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br>在深度学习中，有时候我们需要对某些节点的梯度进行一些定制，特别是该节点操作不可导（比如阶梯除法如$10 // 3 = 3$），如果实在需要对这个节点进行操作，而且希望其可以反向传播，那么就需要对其进行自定义反向传播时的梯度。在有些场景，如[2]中介绍到的<strong>梯度反转</strong>(gradient inverse)中，就必须在某层节点对反向传播的梯度进行反转，也就是需要更改正常的梯度传播过程，如下图的$-\lambda \dfrac{\partial L_d}{\partial \theta_f}$所示。<br><img src="/imgs/tensorflow/tf_gradient/inversenet.png" alt="inversenet"></p><p>在tensorflow中有若干可以实现定制梯度的方法，这里介绍两种。</p><hr><h1 id="1-重写梯度法"><a href="#1-重写梯度法" class="headerlink" title="1. 重写梯度法"></a>1. 重写梯度法</h1><p>重写梯度法指的是通过tensorflow自带的机制，将某个节点的梯度重写(override)，这种方法的适用性最广。我们这里举个例子[3].</p><p>符号函数的前向传播采用的是阶跃函数$y = \rm{sign}(x)$，如下图所示，我们知道阶跃函数不是连续可导的，因此我们在反向传播时，将其替代为一个可以连续求导的函数$y = \rm{Htanh(x)}$，于是梯度就是大于1和小于-1时为0，在-1和1之间时是1。<br><img src="/imgs/tensorflow/tf_gradient/ops.png" alt="ops"></p><p>使用重写梯度的方法如下，主要是涉及到<code>tf.RegisterGradient()</code>和<code>tf.get_default_graph().gradient_override_map()</code>，前者注册新的梯度，后者重写图中具有名字<code>name=&#39;Sign&#39;</code>的操作节点的梯度，用在新注册的<code>QuantizeGrad</code>替代。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用修饰器，建立梯度反向传播函数。其中op.input包含输入值、输出值，grad包含上层传来的梯度</span></span><br><span class="line"><span class="meta">@tf.RegisterGradient("QuantizeGrad")</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sign_grad</span><span class="params">(op, grad)</span>:</span></span><br><span class="line">    input = op.inputs[<span class="number">0</span>] <span class="comment"># 取出当前的输入</span></span><br><span class="line">    cond = (input&gt;=<span class="number">-1</span>)&amp;(input&lt;=<span class="number">1</span>) <span class="comment"># 大于1或者小于-1的值的位置</span></span><br><span class="line">    zeros = tf.zeros_like(grad) <span class="comment"># 定义出0矩阵用于掩膜</span></span><br><span class="line">    <span class="keyword">return</span> tf.where(cond, grad, zeros) </span><br><span class="line">    <span class="comment"># 将大于1或者小于-1的上一层的梯度置为0</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#使用with上下文管理器覆盖原始的sign梯度函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary</span><span class="params">(input)</span>:</span></span><br><span class="line">    x = input</span><br><span class="line">    <span class="keyword">with</span> tf.get_default_graph().gradient_override_map(&#123;<span class="string">"Sign"</span>:<span class="string">'QuantizeGrad'</span>&#125;):</span><br><span class="line">    <span class="comment">#重写梯度</span></span><br><span class="line">        x = tf.sign(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"> </span><br><span class="line"><span class="comment">#使用</span></span><br><span class="line">x = binary(x)</span><br></pre></td></tr></table></figure><p>其中的<code>def sign_grad(op, grad):</code>是注册新的梯度的套路，其中的<code>op</code>是当前操作的输入值/张量等，而<code>grad</code>指的是从反向而言的上一层的梯度。</p><hr><p>通常来说，在tensorflow中自定义梯度，函数<code>tf.identity()</code>是很重要的，其API手册如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.identity(</span><br><span class="line">    input,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p>其会返回一个形状和内容都和输入完全一样的输出，但是你可以自定义其反向传播时的梯度，因此在梯度反转等操作中特别有用。<br>这里再举个反向梯度[2]的例子，也就是梯度为$-\lambda \dfrac{\partial L_d}{\partial \theta_f}$而不是$\lambda \dfrac{\partial L_d}{\partial \theta_f}$。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x1 = tf.Variable(<span class="number">1</span>)</span><br><span class="line">x2 = tf.Variable(<span class="number">3</span>)</span><br><span class="line">x3 = tf.Variable(<span class="number">6</span>)</span><br><span class="line"><span class="meta">@tf.RegisterGradient('CustomGrad')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">CustomGrad</span><span class="params">(op, grad)</span>:</span></span><br><span class="line"><span class="comment">#     tf.Print(grad)</span></span><br><span class="line">    <span class="keyword">return</span> -grad</span><br><span class="line">    </span><br><span class="line">g = tf.get_default_graph()</span><br><span class="line">oo = x1+x2</span><br><span class="line"><span class="keyword">with</span> g.gradient_override_map(&#123;<span class="string">"Identity"</span>: <span class="string">"CustomGrad"</span>&#125;):</span><br><span class="line">    output = tf.identity(oo)</span><br><span class="line">grad_1 = tf.gradients(output, oo)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(grad_1))</span><br></pre></td></tr></table></figure></p><p>因为<code>-grad</code>，所以这里的梯度输出是[-1]而不是[1]。有一个我们需要注意的是，在自定义函数<code>def CustomGrad()</code>中，返回的值得是一个张量，而不能返回一个参数，比如<code>return 0</code>，这样会报错，如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AttributeError: <span class="string">'int'</span> object has no attribute <span class="string">'name'</span></span><br></pre></td></tr></table></figure></p><p>显然，这是因为tensorflow的内部操作需要取返回值的名字而<code>int</code>类型没有名字。</p><p><strong>PS:</strong><code>def CustomGrad()</code>这个函数签名是随便你取的。</p><hr><h1 id="2-stop-gradient法"><a href="#2-stop-gradient法" class="headerlink" title="2. stop_gradient法"></a>2. stop_gradient法</h1><p>对于自定义梯度，还有一种比较简洁的操作，就是利用<code>tf.stop_gradient()</code>函数，我们看下例子[1]：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t = g(x)</span><br><span class="line">y = t + tf.stop_gradient(f(x) - t)</span><br></pre></td></tr></table></figure></p><p>这里，我们本来的前向传递函数是f(x)，但是想要在反向时传递的函数是g(x)，因为在前向过程中，<code>tf.stop_gradient()</code>不起作用，因此<code>+t</code>和<code>-t</code>抵消掉了，只剩下f(x)前向传递；而在反向过程中，因为<code>tf.stop_gradient()</code>的作用，使得f(x)-t的梯度变为了0，从而只剩下g(x)在反向传递。<br>我们看下完整的例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x1 = tf.Variable(<span class="number">1</span>)</span><br><span class="line">x2 = tf.Variable(<span class="number">3</span>)</span><br><span class="line">x3 = tf.Variable(<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">f = x1+x2*x3</span><br><span class="line">t = -f</span><br><span class="line"></span><br><span class="line">y1 =  t + tf.stop_gradient(f-t)</span><br><span class="line">y2 = f</span><br><span class="line"></span><br><span class="line">grad_1 = tf.gradients(y1, x1)</span><br><span class="line">grad_2 = tf.gradients(y2, x1)</span><br><span class="line"><span class="keyword">with</span> tf.Session(config=config) <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    print(sess.run(grad_1))</span><br><span class="line">    print(sess.run(grad_2))</span><br></pre></td></tr></table></figure></p><p>第一个输出为[-1]，第二个输出为[1]，显然也实现了梯度的反转。</p><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1]. <a href="https://stackoverflow.com/questions/36456436/how-can-i-define-only-the-gradient-for-a-tensorflow-subgraph/36480182#36480182" target="_blank" rel="noopener">How Can I Define Only the Gradient for a Tensorflow Subgraph?</a><br>[2]. Ganin Y, Ustinova E, Ajakan H, et al. Domain-adversarial training of neural networks[J]. Journal of Machine Learning Research, 2017, 17(1):2096-2030.<br>[3]. <a href="https://blog.csdn.net/qq_16234613/article/details/82937867">tensorflow 实现自定义梯度反向传播</a><br>[4]. <a href="https://uoguelph-mlrg.github.io/tensorflow_gradients/" target="_blank" rel="noopener">Custom Gradients in TensorFlow</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;在深度学习中，有时候我们需要对某些节点的梯度进行一些定制，特别是该节点操作不可导（比如阶梯除法如$10 // 3 = 3$），如果实在需要对这个节点进行操作，而且希望其可以反向传播，那么就需要对其进行自定
      
    
    </summary>
    
      <category term="TensorFlow Basic API" scheme="https://blog.csdn.net/LoseInVain/categories/TensorFlow-Basic-API/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="https://blog.csdn.net/LoseInVain/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>SVM沉思录6——支持向量机中的核技巧那些事儿</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/21/svm/svm6/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/21/svm/svm6/</id>
    <published>2018-10-21T04:16:07.946Z</published>
    <updated>2018-10-21T02:12:10.976Z</updated>
    
    <content type="html"><![CDATA[<font size="6"><b>前言</b></font> <p><strong>我们在前文[1-5]中介绍了线性支持向量机的原理和推导，涉及到了软和硬的线性支持向量机，还有相关的广义拉格朗日乘数法和KKT条件等。然而，光靠着前面介绍的这些内容，只能够对近似于线性可分的数据进行分割，而不能对非线性的数据进行处理，这里我们简单介绍下支持向量机中使用的核技巧，使用了核技巧的支持向量机就具备了分割非线性数据的能力。本篇可能是我们这个系列的最后一篇了，如果有机会我们在SMO中再会吧。</strong></p><p><strong>如有谬误，请联系指正。转载请注明出处。</strong></p><p><em>联系方式：</em><br><strong>e-mail</strong>: <code>FesianXu@163.com</code><br><strong>QQ</strong>: <code>973926198</code><br><strong>github</strong>: <code>https://github.com/FesianXu</code></p><hr><h1 id="重回SVM"><a href="#重回SVM" class="headerlink" title="重回SVM"></a>重回SVM</h1><p>我们在前文[1-5]中就线性SVM做了比较系统的介绍和推导，我们这里做个简单的小回顾。<strong>支持向量机</strong>(Support Vector Machine,SVM)，是一种基于最大间隔原则进行推导出来的线性分类器，如果引入松弛项，则可以处理近似线性可分的一些数据，其最终的对偶问题的数学表达形式为(1.1)，之所以用对偶形式求解是因为可以轻松地引入所谓的核技巧，我们后面将会看到这个便利性。</p><script type="math/tex; mode=display">\min_{\alpha}\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_jy_iy_j(x_i \cdot x_j)- \sum_{i=1}^N\alpha_i \\s.t. \ \sum_{i=1}^N\alpha_iy_i=0 \\\alpha_i \geq0,i=1,\cdots,N\tag{1.1}</script><p>其最终的分类超平面如(1.2):</p><script type="math/tex; mode=display">\theta(x) = \rm{sign}(\sum_{i=1}^N \alpha^*_iy_i(x_i \cdot x)+b^*)\tag{1.2}</script><p>从KKT条件[3]中我们知道，除了支持向量SV会影响到决策面之外，其他所有的样本都是不会对决策面产生影响的，因此只有支持向量对应的$\alpha_i^* &gt; 0$，其他所有的$\alpha_j^*$都是等于0的。也就是说，我们的支持向量机只需要记住某些决定性的样本就可以了。<strong>实际上，这种需要“记住样本”的方法，正是一类核方法(kernel method)。</strong>这个我们后面可能会独立一些文章进行讨论，这里我们记住，因为SVM只需要记忆很少的一部分样本信息，因此被称之为<strong>稀疏核方法</strong>(Sparse Kernel Method)[6]。</p><hr><h1 id="更进一步观察SVM"><a href="#更进一步观察SVM" class="headerlink" title="更进一步观察SVM"></a>更进一步观察SVM</h1><p>我们这里更进一步对SVM的对偶优化任务和决策面，也即是式子(1.1)(1.2)进行观察，我们会发现，有一个项是相同作用的，那就是$(x_i \cdot x_j)$和$(x_i \cdot x)$，这两项都是在<strong>度量两个样本之间的距离</strong>。我们会发现，因为点积操作</p><script type="math/tex; mode=display">x_i \cdot x_j = ||x_i|| \cdot ||x_j|| \cdot \cos(\theta)\tag{2.1}</script><p>在两个向量模长相同的情况下，可以知道这个点积的结果越大，两个样本之间的相似度越高，因此可以看作是一种样本之间的<strong>度量</strong>(metric)。这个我们可以理解，SVM作为一种稀疏核方法的之前就是一个核方法，是需要纪录训练样本的原始信息的。</p><p>但是，我们注意到，我们是在<strong>原始的样本特征空间进行对比这个相似度的</strong>，这个很关键，因为在原始的样本特征空间里面，<strong>样本不一定是线性可分的，如果在这个空间里面，线性SVM将没法达到很好的效果。</strong></p><hr><h1 id="开始我们的非线性之路"><a href="#开始我们的非线性之路" class="headerlink" title="开始我们的非线性之路"></a>开始我们的非线性之路</h1><p>那么，我们在回顾了之前的一些东西之后，我们便可以开始我们的非线性之路了，抓好扶手吧，我们要起飞了。</p><h2 id="高维映射"><a href="#高维映射" class="headerlink" title="高维映射"></a>高维映射</h2><p>对于非线性的数据，如下图所示，显然我们没法通过一个线性平面对其进行分割。<br><img src="/imgs/svm/raw_feature.png" alt="raw_feature"><br>当然，那仅仅是在二维的情况下我们没法对齐进行线性分割，谁说我们不能在更高的维度进行“维度打击”呢？！<strong>我们不妨把整个数据上升一个维度，投射到三维空间</strong>，我们将红色数据“拉高”，而绿色数据“留在原地”，那么我们就有了：<br><img src="/imgs/svm/projected_feature.png" alt="projected_feature"><br>发现没有，在二维线性不可分的数据，在三维空间就变得线性可分了。这个时候我们可以纪录下在三维情况下的决策面，然后在做个逆操作，将其投射到原先的二维空间中，那么我们就有了:<br><img src="/imgs/svm/recover.png" alt="recover"><br>看来这种维度打击还真是有效！</p><p>$\nabla$<strong>我们其实还可以再举个更为简单的例子。</strong>$\nabla$<br>假如我们现在有一些数据，满足$x_1^2+x_2^2=1$，是的，我们不难发现这其实就是个以原点为圆心半径为1的圆，其参数为$x_1$和$x_2$，但是显然的，这个是个非线性的关系，如果要转换成一个线性的关系要怎么操作呢？简单，用$x_3 = x_1^2$和$x_4 = x_2^2$，我们有变形等价式$x_3+x_4=1$，于是我们便有了关于$x_3$和$x_4$的线性关系式，其关键就是映射$\phi(x)=x^2$。</p><p>别小看这个例子哦，这个是我们核技巧的一个关键的直观想法哦。没晕吧？让我们继续吧。</p><h1 id="基函数"><a href="#基函数" class="headerlink" title="基函数"></a>基函数</h1><p>其实我们刚才举得例子中的$\phi(x) = x^2$就是一个<strong>基函数</strong>(basic function)，其作用很直接，就是将一个属于特征空间$\mathcal{M}$的样本$\mathbf{x} \in \mathcal{M}$映射到新的特征空间$\mathcal{N}$，使得有$\phi(\mathbf{x}) \in \mathcal{N}$。如果诸位看官熟悉深度学习，那么我们就会发现，其实<strong>深度学习中的激活函数无非也就是起着这种作用，将浅层的特征空间映射到深层的特征空间，使得其尽可能地容易区分。可以说，激活函数就是一种基函数。</strong></p><p>那么我们能不能把这种映射应用到，我们刚才的第二节提到的度量测试中的原始特征空间中的样本呢？答案自然是可以的，这样，我们就会有：</p><script type="math/tex; mode=display">(\phi(\mathbf{x}_i) \cdot \phi(\mathbf{x_j}))\tag{3.1}</script><p>通常为了后续讨论，我们会将式子(3.1)表示为(3.2):</p><script type="math/tex; mode=display">\mathcal{k}(\mathbf{x}_i, \mathbf{x}_j) = (\phi(\mathbf{x}_i) \cdot \phi(\mathbf{x_j})) = \phi(\mathbf{x}_i)^T\phi(\mathbf{x}_j)\tag{3.2}</script><p>好的，这样我们就将原始特征空间的样本映射到新的特征空间了，这个特征空间一般来说是更高维的线性可分的空间。我们将这里的$\mathcal{k}(\cdot, \cdot)$称之为<strong>核函数</strong>(kernels)，哦噢，我们的核函数正式出场了哦。</p><p>在给定了核函数的情况下，我们的对偶优化问题和决策面变成了：</p><script type="math/tex; mode=display">\min_{\alpha}\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_jy_iy_j \mathcal{k}(x_i \cdot x_j)- \sum_{i=1}^N\alpha_i \\s.t. \ \sum_{i=1}^N\alpha_iy_i=0 \\\alpha_i \geq0,i=1,\cdots,N\tag{3.3 对偶问题}</script><script type="math/tex; mode=display">\theta(x) = \rm{sign}(\sum_{i=1}^N \alpha^*_iy_i \mathcal{k}(x_i \cdot x)+b^*)\tag{3.4 决策面}</script><p>但是，实际上我们是人工很难找到这个合适的映射$\phi(\cdot)$的，特别是在数据复杂，而不是像例子那样的时候，那么我们该怎么办呢？我们能不能直接给定一个核函数$\mathcal{k}(\cdot, \cdot)$，然后就不用理会具体的基函数了呢？这样就可以隐式地在特征空间进行特征学习，而不需要显式地指定特征空间和基函数$\phi(\cdot)$[9]。答案是可以的！</p><p>我们给定一个<strong>Mercer定理</strong>[10]：</p><blockquote><p>如果函数$\mathcal{k}(\cdot, \cdot)$是$\mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$上的映射（也就是从两个n维向量映射到实数域，既是进行样本度量计算）。那么如果$\mathcal{k}(\cdot, \cdot)$是一个有效核函数（也称为Mercer核函数），那么当且仅当对于训练样例$[x^{(1)}, x^{(2)}, \cdots, x^{(m)}]$，其相应的核函数矩阵是对称半正定(positive semidefinite)的，并且有$\mathcal{k}(x,y) = \mathcal{k}(y,x)$。</p></blockquote><p>嗯，定理很长，人生很短，这个定理说人话就是，如果这个核函数$\mathcal{k}(\cdot, \cdot)$是一个对称半正定的，并且其是个对称函数（度量的基本条件），那么这个核函数就肯定对应了某个样本与样本之间的度量，其关系正如(3.2)所示，因此隐式地定义出了样本的映射函数$\phi(\cdot)$，因此是个有效的核函数。</p><p>诶，但是对称半正定不是矩阵才能判断吗？这里的核函数是个函数耶？嗯…也不尽然，休息下，我们下一节继续吧。</p><h2 id="无限维向量与希尔伯特空间"><a href="#无限维向量与希尔伯特空间" class="headerlink" title="无限维向量与希尔伯特空间"></a>无限维向量与希尔伯特空间</h2><p>先暂时忘记之前的东西吧，清清脑袋，轻装上阵。我们在以前学习过得向量和矩阵都是有限维度的，那么是否存在<strong>无限维</strong>的向量和矩阵呢？其实，<strong>函数</strong>正是可以看成<strong>无限维的向量</strong>，想法其实很简单，假如有一个数值函数$f:x \rightarrow y$，假设其定义域是整个实数，如果对应每一个输入，都输出一个输出值，我们可以把所有输出值排列起来，也就形成了一个无限维的向量，表达为${y}^{\infty}_i$。</p><p>而核函数$\mathcal{k}(\mathbf{x}_i, \mathbf{x}_j)$作为一个双变量函数，就可以看成一个行列都是无限维的矩阵了。这样我们就可以定义其正定性了：</p><script type="math/tex; mode=display">\int\int f(\mathbf{x})\mathcal{k}(\mathbf{x}, \mathbf{y})f(\mathbf{y}) \rm{d} \mathbf{x} \rm{d} \mathbf{y} \geq 0\tag{3.5}</script><p>既然是个矩阵，那么我们就可以对其进行特征分解对吧，只不过因为是无限维，我们需要使用积分，表达式类似于矩阵的特征值分解：</p><script type="math/tex; mode=display">\int \mathcal{k}(\mathbf{x}, \mathbf{y}) \Phi(\mathbf{x}) \rm{d} \mathbf{x} = \lambda \Phi(\mathbf{y})\tag{3.6}</script><p>这里的特征就不是<strong>特征向量</strong>了，而是<strong>特征函数</strong>（看成无限维向量也可以的）。对于不同的特征值$\lambda_1$和$\lambda_2$，和对应的特征函数$\Phi_1(\mathbf{x})$和$\Phi_2(\mathbf{x})$，有：</p><script type="math/tex; mode=display">\begin{aligned}\int \mathcal{k}(\mathbf{x}, \mathbf{y}) \Phi_1(\mathbf{x}) \Phi_2(\mathbf{x}) \rm{d} \mathbf{x} &= \int \mathcal{k}(\mathbf{x}, \mathbf{y}) \Phi_2(\mathbf{x}) \Phi_1(\mathbf{x}) \rm{d} \mathbf{x} \\\rightarrow \int \lambda_1 \Phi_1(\mathbf{x}) \Phi_2(\mathbf{x}) \rm{d} \mathbf{x} &= \int \lambda_2 \Phi_2(\mathbf{x}) \Phi_1(\mathbf{x}) \rm{d} \mathbf{x}\end{aligned}\tag{3.7}</script><p>因为特征值不为0，因此由(3.7)我们有:</p><script type="math/tex; mode=display">< \Phi_1,  \Phi_2 > = \int \Phi_1(\mathbf{x}) \Phi_2(\mathbf{x}) \rm{d} \mathbf{x} = 0\tag{3.8}</script><p>也就是任意两个特征函数之间是<strong>正交</strong>(Orthogonal)的，一个核函数对应着无限个特征值${\lambda_i}_{i=1}^{\infty}$和无限个特征函数${\Phi_i}_{i=1}^{\infty}$，这个正是原先函数空间的一组正交基。</p><p>回想到我们以前学习到的矩阵分解，我们知道我们的矩阵$A$可以表示为：</p><script type="math/tex; mode=display">A = Q\Lambda Q^T\tag{3.9}</script><p>其中$Q$是$A$的特征向量组成的正交矩阵，$\Lambda$是对角矩阵。特征值$\Lambda_{i,i}$对应的特征向量是矩阵$Q$的第$i$列。我们看到在有限维空间中可以将矩阵表示为特征向量和特征值的组合表达。同样的，在无限维空间中，也可以定义这种分解，因此可以将核函数$\mathcal{k}(\cdot,\cdot)$表示为:</p><script type="math/tex; mode=display">\mathcal{k}(\mathbf{x}, \mathbf{y}) = \sum_{i=0}^{\infty} \lambda_i \Phi_i(\mathbf{x}) \Phi_i(\mathbf{y})\tag{3.10}</script><p>重新整理下，将${\sqrt{\lambda_i}\Phi_i}_{i=1}^{\infty}$作为一组正交基，构建出一个空间$\mathcal{H}$。不难发现，这个空间是无限维的，如果再深入探讨，还会发现他是完备的内积空间，因此被称之为<strong>希尔伯特空间</strong>(Hilbert space)[13]。别被名字给唬住了，其实就是将欧几里德空间的性质延伸到了无限维而已。</p><p>回到我们的希尔伯特空间，我们会发现，这个空间中的任意一个函数（向量）都可以由正交基进行线性表出：</p><script type="math/tex; mode=display">f = \sum_{i=1}^{\infty} f_i \sqrt{\lambda_i} \Phi_i\tag{3.11}</script><p>所以$f$可以表示为空间$\mathcal{H}$中的一个无限维向量：</p><script type="math/tex; mode=display">f = (f_1, f_2, \cdots,)^T_{\mathcal{H}}\tag{3.12}</script><h2 id="再生性-Reproduce"><a href="#再生性-Reproduce" class="headerlink" title="再生性(Reproduce)"></a>再生性(Reproduce)</h2><p>前面3.3讨论了很多关于函数在希尔伯特空间上的表出形式，我们这里在仔细观察下核函数。我们发现，其实核函数可以拆分为：</p><script type="math/tex; mode=display">\mathcal{k}(\mathbf{x}, \mathbf{y}) = \sum_{i=0}^{\infty}\lambda_i\Phi_i(\mathbf{x})\Phi_i(\mathbf{y}) = < \mathcal{k}(\mathbf{x},\cdot), \mathcal{k}(\mathbf{y}, \cdot) >_{\mathcal{H}}\tag{3.13}</script><p>其中:</p><script type="math/tex; mode=display">\mathcal{k}(\mathbf{x}, \cdot) = (\sqrt{\lambda_1}\Phi_1(\mathbf{x}),\sqrt{\lambda_2}\Phi_2(\mathbf{x}),\cdots)^T_{\mathcal{H}} \\\mathcal{k}(\mathbf{y}, \cdot) = (\sqrt{\lambda_1}\Phi_1(\mathbf{y}),\sqrt{\lambda_2}\Phi_2(\mathbf{y}),\cdots)^T_{\mathcal{H}}\tag{3.14}</script><p>发现没有，(3.13)将核函数表示为了两个函数的内积，是不是很想我们的式子(3.2)了呢。我们把这种可以用核函数来再生出两个函数的内积的这种性质称之为<strong>再生性</strong>(reproduce)，对应的希尔伯特空间称之为<strong>再生核希尔伯特空间</strong>(Reproducing Kernel Hilbert Space,RKHS)，有点吓人的名词，但是如果你能理解刚才的分解，这个其实还是蛮直接的。</p><p>我们更进一步吧，如果定义一个映射$\phi(\cdot)$:</p><script type="math/tex; mode=display">\phi(\mathbf{x}) = (\sqrt{\lambda_1}\Phi_1(\mathbf{x}),\sqrt{\lambda_2}\Phi_2(\mathbf{x}),\cdots)^T\tag{3.15}</script><p>当然这是个无限维的向量。这个映射将样本点$\mathbf{x} \in \mathbb{R}^n$投射到无限维的特征空间$\mathcal{H}$中，我们有：</p><script type="math/tex; mode=display">< \phi(\mathbf{x}), \phi(\mathbf{y}) > = \mathcal{k}(\mathbf{x}, \mathbf{y}) = \phi(\mathbf{x})^T\phi(\mathbf{y})\tag{3.16}</script><p>因此，我们解决了3.2中提出的问题，我们根本就不需要知道具体的映射函数$\phi$是什么形式的，特征空间在哪里（我们甚至可以投射到无限维特征空间，比如我们接下来要讲到的高斯核函数），只要是一个对称半正定的核函数$K$，那么就必然存在映射$\phi$和特征空间$\mathcal{H}$，使得式子(3.16)成立。</p><p>这就是所谓的<strong>核技巧</strong>(Kernel trick)[12]。</p><p><strong>PS:</strong> 为了理解为什么是从原始的有限维的特征空间映射到无限维的希尔伯特空间，我们从式子(3.15)其实不难发现，$\mathbf{x} \in \mathbb{R}^n$，$\sqrt{\lambda_i}\Phi_i(\mathbf{x}) \in \mathbb{R}$，而我们的$i \rightarrow \infty$，因此可以看成映射成了无限维的特征。</p><h2 id="高斯核函数的无限维映射性质"><a href="#高斯核函数的无限维映射性质" class="headerlink" title="高斯核函数的无限维映射性质"></a>高斯核函数的无限维映射性质</h2><p>有效的核函数，也就是对称半正定的核函数有很多，而且有一定的性质可以扩展组合这些核函数[6]，这一块内容比较多，我们以后独立一篇文章继续讨论。这里我们主要看下使用最多的核函数，<strong>高斯核函数</strong>，也经常称之为<strong>径向基函数</strong>。</p><p>高斯核函数的数学表达形式如下所示：</p><script type="math/tex; mode=display">\mathcal{k}(\mathbf{x}, \mathbf{y}) = \exp(-||\mathbf{x}-\mathbf{y}||^2/2\sigma^2)\tag{3.17}</script><p>我们现在对(3.17)进行变形(这里为了方便假设$\mathbf{x},\mathbf{y}$是一维的)：</p><script type="math/tex; mode=display">\begin{aligned}\exp(-||x-y||^2/2\sigma^2) &= \exp(-\lambda||x-y||^2) \\&= \exp(-\lambda x^2+2\lambda xy-\lambda y^2) \\&= \exp(-\lambda x^2) \exp(-\lambda y^2) \exp(2\lambda xy)\end{aligned}\tag{3.18}</script><p>利用泰勒展开[14]对式子(3.18)中的$\exp(2\lambda xy)$进行展开，有:</p><script type="math/tex; mode=display">\begin{aligned}\exp(2\lambda xy) &= \sum_{i=1}^{\infty} \dfrac{(2\lambda xy)^i}{i!} \\&= \sum_{i=1}^{\infty} \sqrt{\dfrac{2^i \lambda}{i!}}x \cdot \sqrt{\dfrac{2^i \lambda}{i!}}y\end{aligned}\tag{3.19}</script><p>现在结合(3.18)和(3.19)，我们有：</p><script type="math/tex; mode=display">\begin{aligned}\exp(-||x-y||^2&/2\sigma^2) \\&= \sum_{i=1}^{\infty} \sqrt{\dfrac{2^i \lambda}{i!}} \exp{(-\lambda x^2)}x \cdot \sqrt{\dfrac{2^i \lambda}{i!}} \exp{(-\lambda y^2)}y\end{aligned}\tag{3.20}</script><p>用序列$\mathbf{x} = {\sqrt{\dfrac{2^1 \lambda}{1!}} \exp{(-\lambda x^2)}x, \sqrt{\dfrac{2^2 \lambda}{2!}} \exp{(-\lambda x^2)}x, \cdots}$, $\mathbf{y}={\sqrt{\dfrac{2^1 \lambda}{1!}} \exp{(-\lambda y^2)}y, \sqrt{\dfrac{2^2 \lambda}{2!}} \exp{(-\lambda y^2)}y,\cdots}$<br>这两个都是无限维向量，也即是一个映射函数$\phi(\cdot)$。于是式子(3.20)可以改写为:</p><script type="math/tex; mode=display">\exp(-||x-y||^2/2\sigma^2) = \mathbf{x}^T \mathbf{y} = \phi(\mathbf{x})^T \phi(\mathbf{y})\tag{3.21}</script><p>看，我们常用的高斯核函数正是一个无限维映射的核函数。</p><hr><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>我们前面对再生核希尔伯特空间进行了简单的介绍，同时了解了无限维映射的核函数，高斯核函数，事实上，我们原始的SVM对偶问题推导中的$(x_i \cdot x_j)$也可以看成一种核函数，只不过这是个线性核函数而已，映射到了原始的特征空间，有：</p><script type="math/tex; mode=display">\mathcal{k}(\mathbf{x}, \mathbf{y}) = \mathbf{x}^T \mathbf{y}\tag{4.1}</script><p>在后续的文章中，我们将会介绍更多的核函数，如多项式核函数对数sigmoid核函数等，同时在后续的文章中，我们也将继续探讨关于基函数的一些应用。</p><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1]. <a href="https://blog.csdn.net/LoseInVain/article/details/78636176">《SVM笔记系列之一》什么是支持向量机SVM</a><br>[2]. <a href="https://blog.csdn.net/LoseInVain/article/details/78636285">《SVM笔记系列之二》SVM的拉格朗日函数表示以及其对偶问题</a><br>[3]. <a href="https://blog.csdn.net/LoseInVain/article/details/78624888">《SVM笔记系列之三》拉格朗日乘数法和KKT条件的直观解释</a><br>[4]. <a href="https://blog.csdn.net/LoseInVain/article/details/78636341">《SVM笔记系列之四》最优化问题的对偶问题</a><br>[5]. <a href="https://blog.csdn.net/LoseInVain/article/details/78646479">《SVM笔记系列之五》软间隔线性支持向量机</a><br>[6]. Bishop C M. Pattern recognition and machine learning (information science and statistics) springer-verlag new york[J]. Inc. Secaucus, NJ, USA, 2006.<br>[7]. Zhang T. An introduction to support vector machines and other kernel-based learning methods[J]. AI Magazine, 2001, 22(2): 103.<br>[8]. <a href="http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html" target="_blank" rel="noopener">Everything You Wanted to Know about the Kernel Trick</a><br>[9]. 李航. 统计学习方法[J]. 2012.<br>[10]. <a href="https://www.cnblogs.com/jerrylead/archive/2011/03/18/1988406.html" target="_blank" rel="noopener">核函数（Kernels） </a><br>[11]. <a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html" target="_blank" rel="noopener">机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用</a><br>[12]. <a href="http://iera.name/a-story-of-basis-and-kernel-part-ii-reproducing-kernel-hilbert-space/" target="_blank" rel="noopener">A Story of Basis and Kernel – Part II: Reproducing Kernel Hilbert Space</a><br>[13]. <a href="https://en.wikipedia.org/wiki/Hilbert_space" target="_blank" rel="noopener">Hilbert space</a><br>[14]. <a href="https://blog.csdn.net/qq_38906523/article/details/79851654">函数的泰勒(Taylor)展开式</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt; 

&lt;p&gt;&lt;strong&gt;我们在前文[1-5]中介绍了线性支持向量机的原理和推导，涉及到了软和硬的线性支持向量机，还有相关的广义拉格朗日乘数法和KKT条件等。然而，光靠着前面介绍的这些内容，只能够对近似于线性可分的数
      
    
    </summary>
    
      <category term="Machine Learning" scheme="https://blog.csdn.net/LoseInVain/categories/Machine-Learning/"/>
    
    
      <category term="Machine Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Machine-Learning/"/>
    
      <category term="SVM" scheme="https://blog.csdn.net/LoseInVain/tags/SVM/"/>
    
      <category term="Kernel Trick" scheme="https://blog.csdn.net/LoseInVain/tags/Kernel-Trick/"/>
    
  </entry>
  
  <entry>
    <title>SVM沉思录5——软间隔线性支持向量机</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/21/svm/svm5/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/21/svm/svm5/</id>
    <published>2018-10-21T04:16:07.945Z</published>
    <updated>2018-10-21T02:04:36.067Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br><strong>在以前的文章中，我们介绍了支持向量机的基本表达式，那是基于硬间隔线性支持向量机的，即是假设数据是完全线性可分的，在数据是近似线性可分的时候，我们不能继续使用硬间隔SVM了，而是需要采用软间隔SVM，在这里我们简单介绍下软间隔线性支持向量机。本人无专业的数学学习背景，只能在直观的角度上解释这个问题，如果有数学专业的朋友，还望不吝赐教。</strong><br><strong>如有误，请联系指正。转载请注明出处。</strong><br><em>联系方式：</em><br><strong>e-mail</strong>: <a href="FesianXu@163.com"><code>FesianXu@163.com</code></a><br><strong>QQ</strong>: <code>973926198</code><br><strong>github</strong>: <a href="https://github.com/FesianXu" target="_blank" rel="noopener"><code>https://github.com/FesianXu</code></a><br><strong>有关代码开源</strong>: <a href="https://github.com/FesianXu/AI_Blog/tree/master/SVM相关" target="_blank" rel="noopener">click</a></p><hr><h1 id="软间隔最大化"><a href="#软间隔最大化" class="headerlink" title="软间隔最大化"></a>软间隔最大化</h1><p>在文章<a href="http://blog.csdn.net/LoseInVain/article/details/78636285">《SVM的拉格朗日函数表示以及其对偶问题》</a>和<a href="http://blog.csdn.net/LoseInVain/article/details/78636176">《SVM支持向量机的目的和起源》</a>中，我们推导了SVM的基本公式，那时的基本假设之一就是<strong>数据是完全线性可分的</strong>，即是总是存在一个超平面$W^TX+b$可以将数据完美的分开，但是正如我们在<a href="http://blog.csdn.net/LoseInVain/article/details/78636285">《SVM的拉格朗日函数表示以及其对偶问题》</a>中最后结尾所说的：</p><blockquote><p>但是，在现实生活中的数据往往是或本身就是非线性可分但是近似线性可分的，或是线性可分但是具有噪声的，以上两种情况都会导致在现实应用中，硬间隔线性支持向量机变得不再实用</p></blockquote><p>因此，我们引入了<strong>软间隔线性支持向量机</strong>这个概念，<strong>硬间隔</strong>和<strong>软间隔</strong>的区别如下图所示：<br><img src="/imgs/svm/hard_margin_svm.png" alt="hard_margin"></p><p><img src="/imgs/svm/soft_margin_svm.png" alt="soft_margin"></p><p>我们的解决方案很简单，就是在软间隔SVM中，我们的分类超平面既要<strong>能够尽可能地将数据类别分对，又要使得支持向量到超平面的间隔尽可能地大</strong>。具体来说，因为线性不可分意味着某些样本点不能满足函数间隔大于等于1的条件，即是$\exists i, 1-y_i(W^Tx_i+b) &gt; 0$。解决方案就是通过对每一个样本点$(x_i, y_i)$引入一个松弛变量$\xi_i \geq 0$，对于那些不满足约束条件的样本点，使得函数间隔加上松弛变量之后大于等于1，于是我们的约束条件就变为了：</p><script type="math/tex; mode=display">y_i(W^T x_i+b)+\xi_i \geq 1 \\= y_i(W^T x_i+b) \geq 1-\xi_i\tag{1.1}</script><p>图像表示如：<br><img src="/imgs/svm/soft_margin_xi.png" alt="soft_margin_xi"></p><p>超平面两侧对称的虚线为支持向量，支持向量到超平面的间隔为1。<strong>在硬间隔SVM中本应该是在虚线内侧没有任何的样本点的，而在软间隔SVM中，因为不是完全的线性可分，所以虚线内侧存在有样本点，通过向每一个在虚线内侧的样本点添加松弛变量$\xi_i$，将这些样本点搬移到支持向量虚线上。而本身就是在虚线外的样本点的松弛变量则可以设为0。</strong><br>于是，给每一个松弛变量赋予一个代价$\xi_i$，我们的目标函数就变成了：</p><script type="math/tex; mode=display">f(W, \xi) = \frac{1}{2} \Vert W \Vert ^2+C \sum_{i=1}^N\xi_i \\i = 1,2, \cdots,N\tag{1.2}</script><p>其中$C &gt; 0$称为<strong>惩罚参数</strong>，C值大的时候对误分类的惩罚增大，C值小的时候对误分类的惩罚减小，$(1.2)$有两层含义：使得$\frac{1}{2} \Vert W \Vert^2$尽量小即是间隔尽可能大，同时使得误分类的数量尽量小，C是调和两者的系数，是一个超参数。<br>于是我们的软间隔SVM的问题可以描述为：</p><script type="math/tex; mode=display">\min_{W,b,\xi} \frac{1}{2} \Vert W \Vert^2+C \sum_{i=1}^N\xi_i \\s.t.　　y_i(W^T x_i+b) \geq 1-\xi_i \\\xi_i \geq 0 \\i = 1,2, \cdots, N\tag{1.3}</script><p>表述为标准形式：</p><script type="math/tex; mode=display">\min_{W,b,\xi} \frac{1}{2} \Vert W \Vert ^2+C \sum_{i=1}^N\xi_i \\s.t.　　1-\xi_i-y_i(W^T x_i+b) \leq 0 \\-\xi_i \leq 0 \\i = 1,2, \cdots, N\tag{1.4}</script><h1 id="软间隔SVM的拉格朗日函数表述和对偶问题"><a href="#软间隔SVM的拉格朗日函数表述和对偶问题" class="headerlink" title="软间隔SVM的拉格朗日函数表述和对偶问题"></a>软间隔SVM的拉格朗日函数表述和对偶问题</h1><p>我们采用<a href="http://blog.csdn.net/LoseInVain/article/details/78636285">《SVM的拉格朗日函数表示以及其对偶问题》</a>中介绍过的相似的方法，将$(1.4)$得到其对偶问题。过程如下：<br>将$(1.4)$转换为其拉格朗日函数形式：</p><script type="math/tex; mode=display">L(W, b, \xi, \alpha, \beta) = \frac{1}{2} \Vert W \Vert^2+C \sum_{i=1}^N\xi_i+\sum_{i=1}^N \alpha_i(1-\xi_i-y_i(W^T x_i+b))- \sum_{i=1}^N \beta_i \xi_i \\= \frac{1}{2} \Vert W \Vert^2+C \sum_{i=1}^N\xi_i+ \sum_{i=1}^N \alpha_i - \sum_{i=1}^N \alpha_i \xi_i - \sum_{i=1}^N \alpha_i y_i(W^T x_i+b) - \sum_{i=1}^N \beta_i \xi_i \\\tag{2.1}</script><p>原问题可以表述为（具体移步<a href="http://blog.csdn.net/loseinvain/article/details/78636341">《最优化问题的对偶问题》</a>）:</p><script type="math/tex; mode=display">\min_{W,b,\xi} \max_{\alpha, \beta} L(W, b, \xi, \alpha, \beta)\tag{2.2}</script><p>得到其对偶问题为：</p><script type="math/tex; mode=display">\max_{\alpha, \beta} \min_{W, b, \xi} L(W, b, \xi, \alpha, \beta)\tag{2.3}</script><p>我们先求对偶问题$\theta_D(\alpha, \beta) = \min_{W, b, \xi} L(W, b, \xi, \alpha, \beta)$，根据KKT条件(具体移步<a href="http://blog.csdn.net/loseinvain/article/details/78624888">《拉格朗日乘数法和KKT条件的直观解释》</a>)，我们有：</p><script type="math/tex; mode=display">\nabla_{W} L(W, b, \xi, \alpha, \beta) = W-\sum_{i=1}^N\alpha_i y_i x_i = 0\tag{2.4}</script><script type="math/tex; mode=display">\nabla_{b} L(W, b, \xi, \alpha, \beta) = \sum_{i=1}^N \alpha_i y_i = 0\tag{2.5}</script><script type="math/tex; mode=display">\nabla_{\xi_i} L(W, b, \xi, \alpha, \beta) = C-\alpha_i-\beta_i = 0\tag{2.6}</script><script type="math/tex; mode=display">\alpha_i \geq 0, \beta_i \geq 0\tag{2.7}</script><p>整理得到：</p><script type="math/tex; mode=display">W = \sum_{i=1}^N\alpha_i y_i x_i \\\sum_{i=1}^N \alpha_i y_i = 0 \\C = \alpha_i+\beta_i\tag{2.8}</script><p>将$(2.8)$代入$(2.1)$，有：</p><script type="math/tex; mode=display">\begin{aligned}L(W, b, \xi, \alpha, \beta) &= \frac{1}{2} \sum_{i=1}^N\alpha_i y_i x_i \sum_{j=1}^N\alpha_j y_j x_j \\&+(\alpha_i+\beta_i)\sum_{i=1}^N \xi_i+\sum_{i=1}^N \alpha_i - \sum_{i=1}^N \alpha_i \xi_i - \sum_{i=1}^N \beta_i \xi_i - \\&\sum_{i=1}^N \alpha_iy_i(\sum_{j=1}^N\alpha_j y_j x_j \cdot x_i +b) \\&= -\frac{1}{2} \sum_{i=1}^N\sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j)+\sum_{i=1}^N \alpha_i\end{aligned}\tag{2.9}</script><p>所以问题变为：</p><script type="math/tex; mode=display">\max_{\alpha, \beta} \theta_D(\alpha, \beta) = \max_{\alpha} -\frac{1}{2} \sum_{i=1}^N\sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j)+\sum_{i=1}^N \alpha_i\tag{2.10}</script><p>表述为最小化问题：</p><script type="math/tex; mode=display">\min_{\alpha} \frac{1}{2} \sum_{i=1}^N\sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j)-\sum_{i=1}^N \alpha_i \\s.t.　　　\sum_{i=1}^N \alpha_i y_i = 0 \\\alpha_i \geq 0 \\\beta_i \geq 0 \\C = \alpha_i+\beta_i\tag{2.11}</script><p>通过将$\beta_i = C-\alpha_i$，$(2.11)$可以化为：</p><script type="math/tex; mode=display">\min_{\alpha} \frac{1}{2} \sum_{i=1}^N\sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j)-\sum_{i=1}^N \alpha_i \\s.t.　　　\sum_{i=1}^N \alpha_i y_i = 0 \\0 \leq \alpha_i \leq C\tag{2.12}</script><p>对比文章<a href="http://blog.csdn.net/LoseInVain/article/details/78636285">《SVM的拉格朗日函数表示以及其对偶问题》</a>中的硬间隔SVM的最终的表达式：</p><script type="math/tex; mode=display">\min_{\alpha}\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_jy_iy_j(x_i \cdot x_j)- \sum_{i=1}^N\alpha_i</script><script type="math/tex; mode=display">s.t. \ \sum_{i=1}^N\alpha_iy_i=0</script><script type="math/tex; mode=display">\alpha_i \geq0,i=1,\cdots,N\tag{2.13}</script><p>不难发现软间隔SVM只是在对拉格朗日乘子$\alpha_i$的约束上加上了一个上界$C$。<br>我们以后都会利用$(2.12)$求解，接下来我们在<strong>SMO算法</strong>中，也将对式子$(2.12)$进行求解。</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ol><li><a href="http://blog.csdn.net/LoseInVain/article/details/78636285">《SVM的拉格朗日函数表示以及其对偶问题》 CSDN</a></li><li><a href="http://blog.csdn.net/LoseInVain/article/details/78636176">《SVM支持向量机的目的和起源》 CSDN</a></li><li><a href="http://blog.csdn.net/loseinvain/article/details/78636341">《最优化问题的对偶问题》 CSDN</a></li><li><a href="http://blog.csdn.net/loseinvain/article/details/78624888">《拉格朗日乘数法和KKT条件的直观解释》 CSDN</a></li><li><a href="https://book.douban.com/subject/10590856/" target="_blank" rel="noopener">《统计学习方法》 豆瓣</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;strong&gt;在以前的文章中，我们介绍了支持向量机的基本表达式，那是基于硬间隔线性支持向量机的，即是假设数据是完全线性可分的，在数据是近似线性可分的时候，我们不能继续使用硬间隔SVM了，而是需要采用软间
      
    
    </summary>
    
      <category term="Machine Learning" scheme="https://blog.csdn.net/LoseInVain/categories/Machine-Learning/"/>
    
    
      <category term="Machine Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Machine-Learning/"/>
    
      <category term="SVM" scheme="https://blog.csdn.net/LoseInVain/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>SVM沉思录4——最优化问题的对偶问题</title>
    <link href="https://blog.csdn.net/LoseInVain/2018/10/21/svm/svm4/"/>
    <id>https://blog.csdn.net/LoseInVain/2018/10/21/svm/svm4/</id>
    <published>2018-10-21T04:16:07.944Z</published>
    <updated>2018-10-21T01:50:27.403Z</updated>
    
    <content type="html"><![CDATA[<p><font size="6"><b>前言</b></font><br><strong>在SVM的推导中，在得到了原问题的拉格朗日函数表达之后，是一个最小最大问题，通常会将其转化为原问题的对偶问题即是最大最小问题进行求解，我们这里简单介绍下最优化问题的对偶问题。本人无专业的数学学习背景，只能在直观的角度上解释这个问题，如果有数学专业的朋友，还望不吝赐教。注意，本文应用多限于SVM，因此会比较狭隘。</strong><br><strong>如有谬误，请联系指正。转载请注明出处。</strong><br><em>联系方式：</em><br><strong>e-mail</strong>: <a href="FesianXu@163.com"><code>FesianXu@163.com</code></a><br><strong>QQ</strong>: <code>973926198</code><br><strong>github</strong>: <a href="https://github.com/FesianXu" target="_blank" rel="noopener"><code>https://github.com/FesianXu</code></a><br><strong>有关代码开源</strong>: <a href="https://github.com/FesianXu/AI_Blog/tree/master/SVM相关" target="_blank" rel="noopener">click</a></p><hr><h1 id="最优化问题"><a href="#最优化问题" class="headerlink" title="最优化问题"></a>最优化问题</h1><p>最优化问题研究的是当函数（目标函数）在给定了一系列的约束条件下的最大值或最小值的问题，一般来说，一个最优化问题具有以下形式：</p><script type="math/tex; mode=display">\min_{x \in R^n} f(x) \\s.t. 　　g_i(x) \leq 0 ,i=1,2,\cdots, N\\　　　   h_j(x) = 0, j=1,2,\cdots, M\tag{1.1}</script><p>最优化问题可以根据<strong>目标函数和约束条件的类型</strong>进行分类: </p><ol><li>如果目标函数和约束条件都为变量的线性函数, 称该最优化问题为<strong>线性规划</strong>;</li><li>如果目标函数为变量的二次函数, 约束条件为变量的仿射函数, 称该最优化问题为<strong>二次规划</strong>; </li><li>如果目标函数或者约束条件为变量的非线性函数, 称该最优化问题为<strong>非线性规划</strong>.</li></ol><hr><h1 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h1><p>最优化问题存在对偶问题，所谓对偶问题，源于这个思想：</p><blockquote><p>原始问题比较难以求解，通过构建其对偶问题，期望解决这个对偶问题得到其原问题的下界（在<strong>弱对偶</strong>情况下，对于最小化问题来说），或者得到原问题的解（<strong>强对偶</strong>情况下）。</p></blockquote><p>在SVM中，因为其属于<strong>凸优化问题</strong>，因此是强对偶问题，可以通过构建对偶问题解决得到原问题的解。<br>我们举一个线性规划中一个经典问题，描述如下：</p><blockquote><p>某工厂有两种原料A、B，而且能用其生产两种产品：</p><ol><li>生产第一种产品需要2个A和4个B，能够获利6；</li><li>生产第二种产品需要3个A和2个B，能够获利4；<br>此时共有100个A和120个B，问该工厂最多获利多少？</li></ol></blockquote><p>可以简单得到其问题的数学表达式为：</p><script type="math/tex; mode=display">\max_{x_1, x_2} 6x_1+4x_2 \\s.t.　　2x_1+3x_2 \leq 100 \\　　　4x_1+2x_2 \leq 120\tag{2.1}</script><p>当然，得到这个式子的根据就是最大化其卖出去的产品的利润。但是，如果只问收益的话，明显地，还可以考虑卖出原材料A和B的手段，前提就是卖出原材料的盈利会比生产商品盈利高，假设产品A和产品B的单价为$w_1$和$w_2$，从这个角度看，只要最小化购买原材料的价格，我们就可以得出另一个数学表达式：</p><script type="math/tex; mode=display">\min_{w_1, w_2} {100w_1+120w_2} \\s.t.　　2w_1+4w_2  \geq 6 \\　　　  3w_1+2w_2 \geq 4\tag{2.2}</script><p><strong>其实，我们可以发现这其实是极大极小问题和其对偶问题，极小极大问题</strong>。</p><hr><h1 id="一些定义"><a href="#一些定义" class="headerlink" title="一些定义"></a>一些定义</h1><h2 id="原始问题"><a href="#原始问题" class="headerlink" title="原始问题"></a>原始问题</h2><p>我们要讨论原问题和对偶问题，就需要一些定义，我们给出原始问题的非拉格朗日函数表达形式如式子$(1.1)$所示，引进其广义拉格朗日函数（详见文章<a href="http://blog.csdn.net/loseinvain/article/details/78624888">《拉格朗日乘数法和KKT条件的直观解释》</a>）：</p><script type="math/tex; mode=display">L(x, \alpha, \beta)_{x \in R^n} = f(x)+\sum_{i=1}^N \alpha_i g_i(x)+\sum_{j=1}^M \beta_j h_j(x)\tag{3.1}</script><p>其中$x=(x^{(1)}, x^{(2)}, \cdots, x^{(n)})^T \in R^n$，而$\alpha_i$和$\beta_j$是拉格朗日乘子，其中由<strong>KKT条件</strong>有$\alpha_i \geq 0$，考虑关于x的函数：</p><script type="math/tex; mode=display">\theta_P(x) = \max_{\alpha, \beta; \alpha_i \geq 0} L(x, \alpha, \beta)\tag{3.2}</script><p>这里下标$P$用以表示这个是原始问题。<br>联想到我们在文章<a href="http://blog.csdn.net/loseinvain/article/details/78636285">《SVM的拉格朗日函数表示以及其对偶问题》</a>中一些关于对偶问题的讨论，我们知道其实$(3.2)$中的$\theta_P(x)$其实就表示了$(1.1)$中的原问题的目标函数和其约束条件，这里再探讨一下：<br><strong>假设我们存在一个x，使得x违反原始问题的约束条件，从而有$g_i(x) &gt; 0$或者$h_j(x) \neq 0$，那么我们可以推论出：</strong></p><script type="math/tex; mode=display">\theta_P(x) = \max_{\alpha, \beta; \alpha_i \geq 0} [f(x)+\sum_{i=1}^N \alpha_i g_i(x)+ \sum_{j=1}^M \beta_j h_j(x)] = + \infty\tag{3.3}</script><p>为什么呢？<strong>因为若存在某个i使得$g_i(x) &gt; 0$， 那么就可以令$\alpha_i \rightarrow +\infty$使得$\theta_P(x$)取得无穷大这个“最大值”；同样的，若存在一个j使得$h_j(x) \neq 0$， 那么就总是可以使得$\beta_j$让$\beta_j h_j(x) \rightarrow +\infty$， 而其他各个$\alpha_i$和$\beta_j$均取为0（满足约束条件的拉格朗日乘子取为0）。这样，只有对于满足约束条件的i和j，才会有$\theta_P(x)=f(x)$成立。</strong>于是我们有这个分段表达式：</p><script type="math/tex; mode=display">\theta_P(x) =\begin{cases}f(x) & x满足原始问题约束 \\+ \infty & 其他\end{cases}\tag{3.4}</script><p>所以，如果是最小化问题，我们有极小极大问题$(3.5)$:</p><script type="math/tex; mode=display">\min_{x} \theta_P(x) = \min_{x} \max_{\alpha, \beta; \alpha_i \geq 0} L(x, \alpha, \beta)\tag{3.5}</script><p><strong>其与式子$(1.1)$是完全等价的，有着同样的解</strong>。这样一来，我们就把原始的最优化问题转换为了广义拉格朗日函数的极小极大问题，为了后续讨论方便，我们记：</p><script type="math/tex; mode=display">p^* = \min_{x} \theta_P(x)\tag{3.6}</script><p>其中$p^*$为问题的解。</p><h2 id="极小极大问题的对偶，-极大极小问题"><a href="#极小极大问题的对偶，-极大极小问题" class="headerlink" title="极小极大问题的对偶， 极大极小问题"></a>极小极大问题的对偶， 极大极小问题</h2><p>我们定义：</p><script type="math/tex; mode=display">\theta_{D} (\alpha, \beta) = \min_{x} L(x, \alpha, \beta)\tag{3.7}</script><p>在考虑极大化$(3.7)$有：</p><script type="math/tex; mode=display">\max_{\alpha, \beta; \alpha_i \geq 0} \theta_D(\alpha, \beta)=\max_{\alpha, \beta; \alpha_i \geq 0} \min_{x} L(x, \alpha, \beta)\tag{3.8}</script><p>式子$(3.8)$称为广义拉格朗日函数的极大极小问题，将其变成约束形式，为：</p><script type="math/tex; mode=display">\max_{\alpha, \beta} \theta_D(\alpha, \beta)=\max_{\alpha, \beta} \min_{x} L(x, \alpha, \beta) \\s.t. 　　\alpha_i \geq 0\tag{3.9}</script><p>式子$(3.9)$被称为原问题的对偶问题，定义其最优解为：</p><script type="math/tex; mode=display">d^* = \max_{\alpha, \beta} \theta_D(\alpha, \beta)\tag{3.10}</script><p>实际上，通过这种方法我们可以将式子$(2.1)$转化为式子$(2.2)$，也就是将原问题转化为对偶问题，有兴趣的朋友可以自行尝试。</p><hr><h1 id="原始问题和对偶问题的关系"><a href="#原始问题和对偶问题的关系" class="headerlink" title="原始问题和对偶问题的关系"></a>原始问题和对偶问题的关系</h1><p>正如前面所谈到的，原始问题的解和对偶问题的解存在一定的关系，对于任意的$\alpha, x, \beta$，我们有：</p><script type="math/tex; mode=display">\theta_D(\alpha, \beta)=\min_{x} L(x, \alpha, \beta) \leq L(x, \alpha, \beta) \leq \max_{\alpha, \beta; \alpha_i \geq 0} L(x, \alpha, \beta)=\theta_P(x)\tag{4.1}</script><p>等价于：</p><script type="math/tex; mode=display">\theta_D(\alpha, \beta) \leq \theta_P(x)\tag{4.2}</script><p>注意，式子$(4.2)$对于所有的$x, \alpha, \beta$都成立，因为原始问题和对偶问题均有最优解，所以有：</p><script type="math/tex; mode=display">\max_{\alpha, \beta; \alpha_i \geq 0} \theta_D(\alpha, \beta) \leq \min_{x} \theta_P(x)\tag{4.3}</script><p>容易得到：</p><script type="math/tex; mode=display">d^* = \max_{\alpha, \beta; \alpha_i \geq 0} \min_{x} L(x, \alpha, \beta) \leq \min_{x} \max_{\alpha, \beta; \alpha_i \geq 0} L(x, \alpha, \beta) = p^*\tag{4.4}</script><p>由此我们得到了在最小化问题中$d^* \leq p^*$的结论，这个称为<strong>弱对偶</strong>。<strong>弱对偶指出，解决最小化问题的对偶问题可以得到原问题的解的下界</strong>。</p><p>既然有弱对偶就会存在<strong>强对偶</strong>。强对偶指的是$d^*=p^*$的情况，在某些情况下，原始问题和对偶问题的解相同，这时可以用解决对偶问题来代替原始问题，下面以定理的方式给出强对偶成立的重要条件而不予以证明：</p><blockquote><p>考虑原始问题$(1.1)$和对偶问题$(3.9)$，假设$f(x)$和$g_i(x)$都是凸函数， $h_j(x)$是仿射函数，并且不等式约束$g_i(x)$是严格可行的，既存在$x$，对所有$i$有$g_i(x) &lt; 0 $，则存在$x^*,\alpha^*,\beta^*$，使得$x^*$是原始问题的解，$\alpha^*,\beta^*$是对偶问题的解（满足这个条件的充分必要条件就是$x^*, \alpha^*, \beta^*$满足KKT条件<sup><a href="#fn_1" id="reffn_1">1</a></sup>），并且：<br>$p^* = d^* = L(x^*, \alpha^*, \beta^*)$</p></blockquote><hr><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ol><li><a href="http://blog.csdn.net/qq_34531825/article/details/52872819">最优化问题学习笔记1-对偶理论 CSDN</a></li><li><a href="https://book.douban.com/subject/10590856/" target="_blank" rel="noopener">《统计学习方法》 豆瓣</a></li><li><a href="https://www.zhihu.com/question/27057384" target="_blank" rel="noopener">如何理解对偶问题？ feng liu的回答</a></li><li><a href="http://blog.csdn.net/loseinvain/article/details/78624888">《拉格朗日乘数法和KKT条件的直观解释》 CSDN</a></li><li><a href="http://blog.csdn.net/loseinvain/article/details/78636285">SVM的拉格朗日函数表示以及其对偶问题 CSDN</a></li></ol><blockquote id="fn_1"><sup>1</sup>. 见<a href="http://blog.csdn.net/loseinvain/article/details/78624888">《拉格朗日乘数法和KKT条件的直观解释》</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;font size=&quot;6&quot;&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;strong&gt;在SVM的推导中，在得到了原问题的拉格朗日函数表达之后，是一个最小最大问题，通常会将其转化为原问题的对偶问题即是最大最小问题进行求解，我们这里简单介绍下最优化问题的对偶问题。本人无专业的数
      
    
    </summary>
    
      <category term="Machine Learning" scheme="https://blog.csdn.net/LoseInVain/categories/Machine-Learning/"/>
    
    
      <category term="Machine Learning" scheme="https://blog.csdn.net/LoseInVain/tags/Machine-Learning/"/>
    
      <category term="SVM" scheme="https://blog.csdn.net/LoseInVain/tags/SVM/"/>
    
  </entry>
  
</feed>
